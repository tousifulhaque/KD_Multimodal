{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9dde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dad3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f344b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  wandb_config import sweep_config\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow_addons.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, Callback\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Add, Dense, LayerNormalization, Normalization , Masking, GlobalAveragePooling1D, Conv1D, Dropout, MultiHeadAttention, Layer\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback, ModelCheckpoint\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.metrics import Recall, Precision , AUC\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7b941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0ba524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1_Score(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.precision_fn = Precision(thresholds=0.5)\n",
    "        self.recall_fn = Recall(thresholds=0.5)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        # since f1 is a variable, we use assign\n",
    "        self.f1.assign(2 * ((p * r) / (p + r + 1e-6)))\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        # we also need to reset the state of the precision and recall objects\n",
    "        self.precision_fn.reset_states()\n",
    "        self.recall_fn.reset_states()\n",
    "        self.f1.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83288736",
   "metadata": {},
   "source": [
    "## Lr Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff9b8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "# from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# class PrintLR(Callback):\n",
    "#     def on_epoch_end(self, epoch, logs = None):\n",
    "\n",
    "\n",
    "def cosine_schedule(base_lr, total_steps, warmup_steps ):\n",
    "    def step_fn(epoch):\n",
    "        lr = base_lr\n",
    "        epoch = 1\n",
    "\n",
    "        progress = (epoch - warmup_steps) / float(total_steps -  warmup_steps)\n",
    "\n",
    "        progress = tf.clip_by_value(progress, 0.0, 1.0)\n",
    "\n",
    "        lr = lr * 0.5 * (1.0 + tf.cos(math.pi * progress))\n",
    "        \n",
    "        if warmup_steps:\n",
    "            lr = lr * tf.minimum(1.0 , epoch/warmup_steps)\n",
    "        \n",
    "        return lr\n",
    "    \n",
    "\n",
    "    return step_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388df218",
   "metadata": {},
   "source": [
    "## Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c02f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEmbedding(Layer):\n",
    "    def __init__(self, units,dropout_rate,  **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "\n",
    "        self.units = units\n",
    "        self.conv_1 = Conv1D(filters  = units, kernel_size = 1)\n",
    "        self.projection = Dense(units, kernel_initializer=TruncatedNormal(stddev=0.02))\n",
    "\n",
    "        self.dropout = Dropout(rate=dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(PositionalEmbedding, self).build(input_shape)\n",
    "\n",
    "        self.position = self.add_weight(\n",
    "            name=\"position\",\n",
    "            shape=(1, input_shape[1], self.units),\n",
    "            initializer=TruncatedNormal(stddev=0.02),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.projection(inputs)\n",
    "        # x = self.conv_1(inputs)\n",
    "        x = x + self.position\n",
    "        return self.dropout(x, training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756111d",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e956fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    def __init__(\n",
    "        self, embed_dim, mlp_dim, num_heads, dropout_rate,\n",
    "        attention_dropout_rate, **kwargs\n",
    "    ):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        #embed_dim = 128, \n",
    "        #mlp_dim = 256\n",
    "        self.mha = MultiHeadAttention(\n",
    "            num_heads = num_heads,\n",
    "            key_dim = embed_dim,\n",
    "            dropout = attention_dropout_rate, \n",
    "            kernel_initializer = TruncatedNormal(stddev = 0.02)\n",
    "        )\n",
    "\n",
    "        self. dense_0 = Dense(\n",
    "            units = mlp_dim, \n",
    "            activation = \"gelu\", \n",
    "            kernel_initializer = TruncatedNormal(stddev = 0.02)\n",
    "        )\n",
    "\n",
    "        self.dense_1 = Dense(\n",
    "            units = embed_dim, \n",
    "            kernel_initializer = TruncatedNormal(stddev = 0.02)\n",
    "        )\n",
    "\n",
    "        self.conv_0 = Conv1D(filters = 4 , kernel_size = 1, activation = 'relu')\n",
    "        self.conv_1 = Conv1D(filters  = embed_dim, kernel_size = 1)\n",
    "\n",
    "        self.dropout_0 = Dropout(rate = dropout_rate)\n",
    "        self.dropout_1 = Dropout(rate = dropout_rate)\n",
    "\n",
    "        self.norm_0 = LayerNormalization(epsilon = 1e-6)\n",
    "        self.norm_1 = LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "        self.add_0 = Add()\n",
    "        self.add_1 = Add()\n",
    "    \n",
    "    def call(self, inputs, training , mask):\n",
    "\n",
    "\n",
    "        x = self.norm_0(inputs)\n",
    "        x = self.mha(\n",
    "            query = x, \n",
    "            value = x, \n",
    "            key = x,\n",
    "            attention_mask = mask,\n",
    "            training = training\n",
    "        ) #[batch_size, sequence_length, embed_dim][8, 500, 3]\n",
    "        x = self.dropout_0(x, training= training)\n",
    "        x = self.add_0([x, inputs])\n",
    "\n",
    "        #MLP block \n",
    "        y = self.norm_1(x)\n",
    "        y = self.conv_0(y) #[batch_size , sequence_length, neurons]\n",
    "#         y = self.dropout_1(y, training)\n",
    "        y = self.conv_1(y)#[batch_size , sequence_lenght, neurons]\n",
    "#         y = self.dropout_1(y, training)\n",
    "        \n",
    "\n",
    "        return self.add_1([x, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e6abf",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af2665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        embed_dim,\n",
    "        mlp_dim,\n",
    "        num_heads,\n",
    "        num_classes,\n",
    "        dropout_rate,\n",
    "        attention_dropout_rate,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "\n",
    "        # Input (normalization of RAW measurements)\n",
    "        self.input_norm = Normalization()\n",
    "        \n",
    "        #Making Layer\n",
    "        self.masking_layer = Masking(mask_value = 0.0)\n",
    "\n",
    "        # Input\n",
    "        self.pos_embs = PositionalEmbedding(embed_dim, dropout_rate)\n",
    "\n",
    "        # Encoder\n",
    "        self.e_layers = [\n",
    "            Encoder(embed_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "        # Output\n",
    "        self.norm = LayerNormalization(epsilon=1e-5)\n",
    "        self.pool = GlobalAveragePooling1D(data_format = 'channels_first')\n",
    "        self.dense_0 = Dense(mlp_dim, activation = 'relu')\n",
    "        self.final_layer = Dense(1, kernel_initializer=\"zeros\", activation = 'sigmoid')\n",
    "\n",
    "    def call(self, inputs, training = True):\n",
    "        expanded_input = tf.cast(tf.tile(tf.expand_dims(inputs, axis=-2), [1, 1, 500,1]), tf.float32)\n",
    "        self.masking_layer.build(expanded_input.shape)\n",
    "        mask = self.masking_layer.compute_mask(expanded_input)\n",
    "        x = self.input_norm(inputs) \n",
    "        x = self.pos_embs(x, training=training)\n",
    "        for layer in self.e_layers:\n",
    "            x = layer(x, training=training , mask = mask)\n",
    "        x = self.norm(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dense_0(x)\n",
    "\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380a929",
   "metadata": {},
   "source": [
    "## Train Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6cc2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "    config = {\n",
    "      'epochs': 50,\n",
    "      'num_layers':  3,\n",
    "      'embed_layer_size': 3,\n",
    "      'global_clipnorm' : 3.0,\n",
    "      'fc_layer_size': 256,\n",
    "      'num_heads': 2,\n",
    "      'dropout': 0.1,\n",
    "      'attention_dropout': 0.1,\n",
    "      'optimizer': 'adam',\n",
    "      'amsgrad': False,\n",
    "      'label_smoothing': 0.1,\n",
    "      'learning_rate': 1e-3,\n",
    "      #'weight_decay': {\n",
    "      #    'values': [2.5e-4, 1e-4, 5e-5, 1e-5]\n",
    "      'warmup_steps': 5,\n",
    "      'batch_size': 8}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "428f63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def create_model():\n",
    "\n",
    "\n",
    "    # config = wandb.config\n",
    "    \n",
    "    # Generate new model\n",
    "    model = Transformer(\n",
    "      num_layers=config['num_layers'],\n",
    "      embed_dim=config['embed_layer_size']\n",
    "      ,\n",
    "      mlp_dim=config['fc_layer_size'],\n",
    "      num_heads=config['num_heads'],\n",
    "      num_classes=2,\n",
    "      dropout_rate=config['dropout'],\n",
    "      attention_dropout_rate=config['attention_dropout'],\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # adapt on training dataset - must be before model.compile !!!\n",
    "    model.input_norm.adapt(X_train, batch_size=config['batch_size'])\n",
    "    # print(model.input_norm.variables)\n",
    "\n",
    "    # Select optimizer\n",
    "    if config['optimizer'] == \"adam\":\n",
    "      optim = Adam(\n",
    "          global_clipnorm=config['global_clipnorm'],\n",
    "          amsgrad=config['amsgrad'],\n",
    "      )\n",
    "    # elif config.optimizer == \"adamw\":\n",
    "    #   optim = AdamW(\n",
    "    #       weight_decay=config.weight_decay,\n",
    "    #       amsgrad=config.amsgrad,\n",
    "    #       global_clipnorm=config.global_clipnorm,\n",
    "    #       exclude_from_weight_decay=[\"position\"]\n",
    "    #   )\n",
    "    else:\n",
    "      raise ValueError(\"The used optimizer is not in list of available\")\n",
    "\n",
    "    model.compile(\n",
    "      loss= BinaryCrossentropy(label_smoothing=config['label_smoothing']),\n",
    "      optimizer=optim,\n",
    "      metrics=[Recall(), Precision() , AUC(), F1_Score()],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8342ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model = create_model()\n",
    "    checkpoint_filepath = os.path.join(os.getcwd(), 'tmp/chekcpoint')\n",
    "    model_checkpoint = ModelCheckpoint(filepath = checkpoint_filepath, \n",
    "                                      save_weights_only = True, \n",
    "                                      monitor = 'val_f1_score', \n",
    "                                      mode = 'max', \n",
    "                                      save_best_only = True, \n",
    "                                      verbose = True)\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "      X_train,\n",
    "      y_train,\n",
    "      batch_size=config['batch_size'],\n",
    "      epochs=config['epochs'],\n",
    "      validation_data=(X_val, y_val),\n",
    "      callbacks=[\n",
    "        LearningRateScheduler(cosine_schedule(base_lr=config['learning_rate'], total_steps=config['epochs'], warmup_steps=config['warmup_steps'])),\n",
    "        EarlyStopping(monitor=\"val_loss\", mode='min', min_delta=0.001, patience=5),\n",
    "        model_checkpoint\n",
    "      ],\n",
    "      verbose=1\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f06f53c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'transformer_2/Tile' defined at (most recent call last):\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_14246/332758909.py\", line 18, in <module>\n      model = train()\n    File \"/tmp/ipykernel_14246/2648363050.py\", line 13, in train\n      history = model.fit(\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_14246/2913373908.py\", line 37, in call\n      expanded_input = tf.cast(tf.tile(tf.expand_dims(inputs, axis=-2), [1, 1, 500,1]), tf.float32)\nNode: 'transformer_2/Tile'\nOOM when allocating tensor with shape[8,500,500,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transformer_2/Tile}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_13087]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# sweep_id = wandb.sweep(sweep_config, project=\"KD_Transformer\")\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/gpu:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [10], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath \u001b[38;5;241m=\u001b[39m checkpoint_filepath, \n\u001b[1;32m      5\u001b[0m                                   save_weights_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      6\u001b[0m                                   monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m                                   mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      8\u001b[0m                                   save_best_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      9\u001b[0m                                   verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLearningRateScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosine_schedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwarmup_steps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/KD_Time/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'transformer_2/Tile' defined at (most recent call last):\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_14246/332758909.py\", line 18, in <module>\n      model = train()\n    File \"/tmp/ipykernel_14246/2648363050.py\", line 13, in train\n      history = model.fit(\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/Students/bgu9/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_14246/2913373908.py\", line 37, in call\n      expanded_input = tf.cast(tf.tile(tf.expand_dims(inputs, axis=-2), [1, 1, 500,1]), tf.float32)\nNode: 'transformer_2/Tile'\nOOM when allocating tensor with shape[8,500,500,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transformer_2/Tile}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_13087]"
     ]
    }
   ],
   "source": [
    "    model = None\n",
    "    dataset_path = os.path.join(os.getcwd(), 'fall_detection_dataset.npz')\n",
    "    f = np.load(dataset_path)\n",
    "    signals = f['trials']\n",
    "\n",
    "    labels = f['labels']\n",
    "\n",
    "    # split to train-test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        signals, labels, test_size=0.15, random_state=9, stratify=labels\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.15, random_state=9, stratify=y_train\n",
    "    )\n",
    "\n",
    "    # sweep_id = wandb.sweep(sweep_config, project=\"KD_Transformer\")\n",
    "    with tf.device('/gpu:0'):\n",
    "      model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b4d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f9ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 12ms/step - loss: 0.6931 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - auc_1: 0.5000 - f1_score: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931473016738892, 0.0, 0.0, 0.5, 0.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=8, steps=X_test.shape[0]/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f10a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = os.path.join(os.getcwd(), 'tmp/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b94247",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/KD_Time/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/KD_Time/lib/python3.9/site-packages/h5py/_hl/files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    525\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    527\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    528\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    529\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    530\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    531\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    532\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 533\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniconda3/envs/KD_Time/lib/python3.9/site-packages/h5py/_hl/files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    225\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    228\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3666a2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Students/bgu9/KD_Transformer/tmp\n"
     ]
    }
   ],
   "source": [
    " cd tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80274147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  chekcpoint.data-00000-of-00001  chekcpoint.index\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc75badd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/Students/bgu9/KD_Transformer/tmp/checkpoint'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81221894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  multiple                 7         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " masking_1 (Masking)         multiple                  0         \n",
      "                                                                 \n",
      " positional_embedding_1 (Pos  multiple                 1512      \n",
      " itionalEmbedding)                                               \n",
      "                                                                 \n",
      " encoder_3 (Encoder)         multiple                  136       \n",
      "                                                                 \n",
      " encoder_4 (Encoder)         multiple                  136       \n",
      "                                                                 \n",
      " encoder_5 (Encoder)         multiple                  136       \n",
      "                                                                 \n",
      " layer_normalization_13 (Lay  multiple                 6         \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling1d_1   multiple                 0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_16 (Dense)            multiple                  128256    \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,446\n",
      "Trainable params: 130,439\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a51ce6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down server on 8888...\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter notebook stop 8888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5543f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
