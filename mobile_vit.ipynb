{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60296eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import math\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fbe1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb57877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow imports \n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback, ModelCheckpoint\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Add, Dense, LayerNormalization,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, MultiHeadAttention, Layer, Embedding\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.metrics import Recall, Precision, AUC\n",
    "\n",
    "#local package import \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#local import \n",
    "from utils import sliding_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84567d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_act(mode = 'train', root_dir = 'dataset/SFDataset', data_type = 'watch_processed', new_len = 128, in_chan =3):\n",
    "    fall = os.path.join(os.getcwd() , f'{root_dir}/{data_type}/{mode}/**/Fall/***.csv')\n",
    "    adl = os.path.join(os.getcwd(), f'{root_dir}/{data_type}/{mode}/**/ADL/***.csv')\n",
    "    fall_files = glob.glob(fall)\n",
    "    adl_files = glob.glob(adl)\n",
    "    all_file_path = fall_files + adl_files\n",
    "    samples = len(all_file_path)\n",
    "    dataset = np.zeros((1,new_len, in_chan))\n",
    "    labels = []\n",
    "    fall_pattern = re.compile(\"Fall\")\n",
    "    \n",
    "    for file_path in all_file_path:\n",
    "        label = None\n",
    "        if fall_pattern.search(file_path):\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        if not df.empty:\n",
    "            df = df.loc[:,'DataCollection__w_accelerometer_x':'DataCollection__w_accelerometer_z']\n",
    "            trial = df.to_numpy()\n",
    "            act_len = trial.shape[0]\n",
    "            channel = trial.shape[1]\n",
    "            interpolated_data = interpolate(new_len, act_len, channel, trial)\n",
    "            dataset = np.concatenate((dataset,interpolated_data), axis = 0)\n",
    "            labels.append(label)\n",
    "    return tf.convert_to_tensor(dataset[1:, :, :]), tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4c65ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset , labels = processing_act(mode = 'val')\n",
    "np.savez('dataset/SFDataset/val',data = dataset, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "aebf92c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(38,), dtype=int32, numpy=\n",
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f98fea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(mode = 'train', root_dir = 'dataset/SmartFall',data_type = 'phone&watch', new_len = 128, in_chan = 3):\n",
    "    fall = os.path.join(os.getcwd() , f'{root_dir}/{data_type}/{mode}/Fall/***.xlsx')\n",
    "    adl = os.path.join(os.getcwd(), f'{root_dir}/{data_type}/{mode}/ADL/***.xlsx')\n",
    "    fall_files = glob.glob(fall)\n",
    "    adl_files = glob.glob(adl)\n",
    "\n",
    "    all_file_path = fall_files + adl_files\n",
    "    samples = len(all_file_path)\n",
    "    dataset = np.zeros((1,new_len, in_chan))\n",
    "    \n",
    "    if len(all_file_path) == 0:\n",
    "        raise Exception('Data files not found')\n",
    " \n",
    "    trials_count = {}\n",
    "    fall_pattern = re.compile(\"Fall\")\n",
    "    trials = []\n",
    "    labels = []\n",
    "    length = []\n",
    "    #count = 0\n",
    "\n",
    "    for file_path in all_file_path:\n",
    "        print(file_path)\n",
    "        label = None\n",
    "        if fall_pattern.search(file_path):\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        #checking if the excel has 2 sheets or not\n",
    "        if len (pd.ExcelFile(file_path).sheet_names) == 2:\n",
    "                df = pd.read_excel(file_path, sheet_name=-1)\n",
    "                df = df.iloc[:, 12:15]\n",
    "                null_col = df[df.isnull().any(axis = 1)].index.to_list()\n",
    "                \n",
    "                if len(null_col) % 10 != 0  :\n",
    "                    print(f'{file_path} trimmed file contains {len(null_col)} of null rows')\n",
    "                    continue\n",
    "                elif len(null_col) == 0:\n",
    "                    trial = df.to_numpy()\n",
    "                    act_len = trial.shape[0]\n",
    "                    channel = trial.shape[1]\n",
    "                    interpolated_data = interpolate(new_len, act_len, channel, trial)\n",
    "                    dataset = np.concatenate((dataset,interpolated_data), axis = 0)\n",
    "                    labels.append(label)\n",
    "\n",
    "                \n",
    "                else:\n",
    "                    #raise Exception(f'{file_path} trimmed file contains {len(null_col)} of null rows')\n",
    "                    #calculating how many null segments we have \n",
    "                    null_col = df[df.isnull().any(axis = 1)].index.to_list()\n",
    "                    print(null_col)\n",
    "                    null_seg = len(null_col)//10\n",
    "\n",
    "\n",
    "                    trial_start_lst = null_col[9::10]\n",
    "                    trial_end_lst = null_col[10::10]\n",
    "\n",
    "                    for i in range(len(null_col)//10 + 1):\n",
    "                        #trials_count[label] = trials_count.get(label , 0) + 1\n",
    "                        trial = None\n",
    "                        if i == 0 :\n",
    "\n",
    "                            #trial = df.iloc[0:null_col[1]-1, 3:6]\n",
    "                            trial = df.iloc[0:null_col[1]-1, :]\n",
    "                        elif i == null_seg :\n",
    "                            #trial = df.iloc[trial_start_lst[-1]+1:, 3:6]\n",
    "                            trial = df.iloc[trial_start_lst[-1]+1:, :]\n",
    "                        else: \n",
    "                            trial_end = trial_end_lst[i-1]\n",
    "                            trial_start = trial_start_lst[i-1] + 1\n",
    "                            #trial = df.iloc[trial_start : trial_end-1 , 3:6]\n",
    "                            trial = df.iloc[trial_start : trial_end-1, : ]\n",
    "                            trial.dropna(inplace = True)\n",
    "\n",
    "                        #trial = tf.convert_to_tensor(trial.values, dtype = tf.float32)\n",
    "                        act_len = trial.shape[0]\n",
    "                        channel = trial.shape[1]\n",
    "                        trial = trial.to_numpy()\n",
    "                        if trial.shape[0] == 0:\n",
    "                            continue\n",
    "\n",
    "                        else:\n",
    "                            interpolated_data = interpolate(new_len, act_len, channel, trial)\n",
    "                            dataset = np.concatenate((dataset,interpolated_data), axis = 0)\n",
    "                            labels.append(label)\n",
    "\n",
    "        else:\n",
    "            raise Exception(f'{file_path} doesnt have trimmed data')\n",
    "        \n",
    "    return tf.convert_to_tensor(dataset[1:, :, :]), tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd857582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(new_len, old_len, channel, data):\n",
    "    x = np.linspace(1, old_len, num = new_len)\n",
    "    xp = np.linspace(1, old_len, num = old_len)\n",
    "    interpolated_data = np.zeros((1, new_len, channel))\n",
    "    \n",
    "    for idx in range(channel):\n",
    "        yp = data[:, idx]\n",
    "        axis_interpolated = np.interp(x, xp, yp)\n",
    "        interpolated_data[0,:, idx] = axis_interpolated\n",
    "    \n",
    "    return interpolated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77678c42",
   "metadata": {},
   "source": [
    "### Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a133251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1_Score(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.precision_fn = Precision(thresholds=0.5)\n",
    "        self.recall_fn = Recall(thresholds=0.5)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        # since f1 is a variable, we use assign\n",
    "        self.f1.assign(2 * ((p * r) / (p + r + 1e-6)))\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        # we also need to reset the state of the precision and recall objects\n",
    "        self.precision_fn.reset_states()\n",
    "        self.recall_fn.reset_states()\n",
    "        self.f1.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9806ad",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16b90978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_schedule(base_lr, total_steps, warmup_steps ):\n",
    "    def step_fn(epoch):\n",
    "        lr = base_lr \n",
    "        progress = (epoch - warmup_steps) / float(total_steps -  warmup_steps)\n",
    "\n",
    "        progress = tf.clip_by_value(progress, 0.0, 1.0)\n",
    "\n",
    "        lr = lr * 0.5 * (1.0 + tf.cos(math.pi * progress))\n",
    "        \n",
    "        if warmup_steps:\n",
    "            lr = lr * tf.minimum(1.0 , epoch/warmup_steps)\n",
    "        \n",
    "        return lr\n",
    "    \n",
    "\n",
    "    return step_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea991f",
   "metadata": {},
   "source": [
    "### Sliding Data into Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c078e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embedding(seq_len,d_model, n = 10000):\n",
    "    P = np.zeros((seq_len, d_model))\n",
    "    for k in range(seq_len):\n",
    "        for i in np.arange(int(d_model/2)):\n",
    "            denominator = np.power(n, 2*i/d_model)\n",
    "            P[k, 2*i] = np.sin(k/denominator)\n",
    "            P[k, 2*i + 1] = np.cos(k/denominator)\n",
    "    P = P[np.newaxis, : ,:]\n",
    "    return tf.Variable(P,trainable = False ,dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afdd83b",
   "metadata": {},
   "source": [
    "### Plot positional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1917e2ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'postional_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      3\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mi)\n\u001b[0;32m----> 4\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mpostional_embedding\u001b[49m, (\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m))\n\u001b[1;32m      5\u001b[0m     cax \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mmatshow(matrix)\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgcf()\u001b[38;5;241m.\u001b[39mcolorbar(cax)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'postional_embedding' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "for i in range(2):\n",
    "    ax = plt.subplot(1, 2, 1+i)\n",
    "    matrix = tf.reshape(postional_embedding, (512, 256))\n",
    "    cax = ax.matshow(matrix)\n",
    "    plt.gcf().colorbar(cax)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d072c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, embed_dim,attn_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate, length, channel):\n",
    "    \n",
    "    #attention_layer\n",
    "    y = LayerNormalization(epsilon = 1e-6)(x)\n",
    "    y = MultiHeadAttention(num_heads = num_heads,key_dim = attn_dim,dropout = attention_dropout_rate, kernel_initializer = TruncatedNormal(stddev = 0.02))(query = x,value = x,key = x,training = True)\n",
    "    y = Dropout(rate = dropout_rate)(y)\n",
    "    y = Add()([x,y])\n",
    "    y = LayerNormalization(epsilon = 1e-6)(y)\n",
    "    res = y\n",
    "    \n",
    "    \n",
    "    #mlp_layer\n",
    "    \n",
    "    y = Dense(units = mlp_dim, kernel_initializer = TruncatedNormal(stddev = 0.02))(y)\n",
    "    y = Dropout(rate = dropout_rate)(y)\n",
    "    y = Conv1D(filters = x.shape[-1],kernel_size = 3,padding = \"same\")(y)\n",
    "    y = Dropout(rate = dropout_rate)(y)\n",
    "    y = Add()([res, y])\n",
    "    y = LayerNormalization(epsilon = 1e-6)(y)\n",
    "    \n",
    "    return y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386f52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(length, channels,num_layers, embed_dim, attn_dim,mlp_dim, num_heads, dropout_rate, attention_dropout_rate):\n",
    "    \n",
    "    #initial normalization\n",
    "    #pos_embed = get_positional_embedding(length, embed_dim)\n",
    "    inputs= keras.Input(shape = (length, channels))\n",
    "    x = inputs\n",
    "    #x = Dense(embed_dim)(inputs)\n",
    "    #x = Normalization()(inputs)\n",
    "    #x = x + pos_embed\n",
    "    #stacking encoder layers\n",
    "    for _ in range(num_layers):\n",
    "        x = encoder(x,embed_dim,attn_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate, length,channels)\n",
    "    #x = LayerNormalization(epsilon=1e-5)(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    for dim in [8, 16]:\n",
    "        x = Dense(dim, activation = 'relu')(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        \n",
    "    #pooling\n",
    "    x = GlobalAveragePooling1D(data_format = 'channels_first')(x)\n",
    "    \n",
    "    #output\n",
    "    output = Dense(1, kernel_initializer=\"zeros\", activation = 'sigmoid')(x)\n",
    "    \n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4e47042",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'epochs': 50,\n",
    "        'length':50,\n",
    "        'channel':3,\n",
    "        'num_layers':  2,\n",
    "        'embed_layer_size': 16,\n",
    "        'attention_head_dim' : 128,\n",
    "        'global_clipnorm' : 3.0,\n",
    "        'fc_layer_size': 32,\n",
    "        'num_heads': 4,\n",
    "        'dropout': 0.1,\n",
    "        'attention_dropout': 0.0,\n",
    "        'optimizer': 'adam',\n",
    "        'amsgrad': False,\n",
    "        'label_smoothing': 0.1,\n",
    "        'learning_rate': 1e-3,\n",
    "        #'weight_decay': {\n",
    "        #    'values': [2.5e-4, 1e-4, 5e-5, 1e-5]\n",
    "        'warmup_steps': 5,\n",
    "        'batch_size': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79000de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer(length = config['length'],\n",
    "        channels=config['channel'],\n",
    "        num_heads=config['num_heads'],\n",
    "        dropout_rate = config['dropout'],\n",
    "        attn_dim = config['attention_head_dim'],\n",
    "        attention_dropout_rate = config['attention_dropout'],\n",
    "        embed_dim =config['embed_layer_size'],\n",
    "        mlp_dim = config['fc_layer_size'], \n",
    "        num_layers = config['num_layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6844d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 50, 3)        7683        input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50, 3)        0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 50, 3)        0           input_1[0][0]                    \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 50, 3)        6           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50, 32)       128         layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 32)       0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 50, 3)        291         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50, 3)        0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 50, 3)        0           layer_normalization_1[0][0]      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 50, 3)        6           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 50, 3)        7683        layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 50, 3)        0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 50, 3)        0           layer_normalization_2[0][0]      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 50, 3)        6           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50, 32)       128         layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 50, 32)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 3)        291         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 50, 3)        0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 50, 3)        0           layer_normalization_4[0][0]      \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 50, 3)        6           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50, 8)        32          layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 50, 8)        0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50, 16)       144         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 16)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 50)           0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            51          global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 16,455\n",
      "Trainable params: 16,455\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32e47d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path, window_size, stride):\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    dataset = dataframe[['w_accelerometer_x', 'w_accelerometer_y', 'w_accelerometer_z']].to_numpy()\n",
    "    labels = dataframe['outcome'].to_numpy()\n",
    "    data, labels= sliding_window(dataset, labels, window_size - 1,dataset.shape[0],window_size,stride)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ee955",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\bgu9\\KD_Multimodal\\new_watch_data_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb6c0e",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af639e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15982, 50)\n",
      "(5088, 50)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = os.path.join(os.getcwd(), 'new_watch_data_processed\\\\watch_train.csv')\n",
    "val_dataset_path = os.path.join(os.getcwd(), 'new_watch_data_processed\\\\watch_val.csv')\n",
    "window_size = 50\n",
    "stride = 5\n",
    "\n",
    "#processing train data \n",
    "X_train, y_train = process_data(train_dataset_path, window_size, stride)\n",
    "#processing val data \n",
    "X_val , y_val = process_data(val_dataset_path, window_size, stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7bd402e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('dataset/sliding50_train', data = X_train, labels = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "def477d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 50, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 50, 3)       7683        ['input_9[0][0]',                \n",
      " HeadAttention)                                                   'input_9[0][0]',                \n",
      "                                                                  'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 50, 3)        0           ['multi_head_attention_16[0][0]']\n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 50, 3)        0           ['input_9[0][0]',                \n",
      "                                                                  'dropout_62[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_49 (LayerN  (None, 50, 3)       6           ['add_32[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 50, 32)       128         ['layer_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 50, 32)       0           ['dense_57[0][0]']               \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 50, 3)        99          ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 50, 3)        0           ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 50, 3)        0           ['layer_normalization_49[0][0]', \n",
      "                                                                  'dropout_64[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 50, 3)       6           ['add_33[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 50, 3)       7683        ['layer_normalization_50[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_50[0][0]', \n",
      "                                                                  'layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_65 (Dropout)           (None, 50, 3)        0           ['multi_head_attention_17[0][0]']\n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 50, 3)        0           ['layer_normalization_50[0][0]', \n",
      "                                                                  'dropout_65[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 50, 3)       6           ['add_34[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 50, 32)       128         ['layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_66 (Dropout)           (None, 50, 32)       0           ['dense_59[0][0]']               \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 50, 3)        99          ['dropout_66[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_67 (Dropout)           (None, 50, 3)        0           ['dense_60[0][0]']               \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 50, 3)        0           ['layer_normalization_52[0][0]', \n",
      "                                                                  'dropout_67[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 50, 3)       6           ['add_35[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 50, 8)        32          ['layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_68 (Dropout)           (None, 50, 8)        0           ['dense_61[0][0]']               \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 50, 16)       144         ['dropout_68[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_69 (Dropout)           (None, 50, 16)       0           ['dense_62[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 50)          0           ['dropout_69[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 1)            51          ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16,071\n",
      "Trainable params: 16,071\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca3eda",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa43285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "      loss= BinaryCrossentropy(label_smoothing=config['label_smoothing']),\n",
    "      optimizer=Adam(\n",
    "          global_clipnorm=config['global_clipnorm'],\n",
    "          amsgrad=config['amsgrad'],\n",
    "      ),\n",
    "      metrics=[Recall(), Precision() , AUC(), F1_Score()],\n",
    "    )\n",
    "checkpoint_filepath = os.path.join(os.getcwd(), 'tmp/weights.ckpt')\n",
    "model_checkpoint = ModelCheckpoint(filepath = checkpoint_filepath, \n",
    "                                      save_weights_only = True, \n",
    "                                      monitor = 'val_f1_score', \n",
    "                                      mode = 'max', \n",
    "                                      save_best_only = True, \n",
    "                                      verbose = True)\n",
    "log_dir = \"logs/\"  # Specify the directory where TensorBoard logs will be saved\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history = model.fit(\n",
    "      X_train,\n",
    "      y_train,\n",
    "      batch_size=config['batch_size'],\n",
    "      epochs=config['epochs'],\n",
    "      validation_data=(X_val, y_val),\n",
    "      shuffle = True,\n",
    "      callbacks=[\n",
    "        LearningRateScheduler(cosine_schedule(base_lr=config['learning_rate'], total_steps=config['epochs'], warmup_steps=config['warmup_steps'])),\n",
    "        #EarlyStopping(monitor=\"loss\", mode='min', min_delta=0.001, patience=5),\n",
    "        model_checkpoint, tensorboard_callback\n",
    "      ],\n",
    "      verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "07f287b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926709b6",
   "metadata": {},
   "source": [
    "### Converting to tflite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c821a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fae1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding special ops\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops. <-- Add this line\n",
    "]\n",
    "converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.allow_custom_ops=True\n",
    "converter.experimental_new_converter =True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "#converting to tflite \n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "884a0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the tflite model to a file \n",
    "with open('transformer_watch50.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37932237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using interpreter to test\n",
    "interpreter = tf.lite.Interpreter(model_path=\"transformer_watch50.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa0ad02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "test_dataset_path = os.path.join(os.getcwd(), 'dataset/SFDataset/test.npz')\n",
    "test_data = np.load(test_dataset_path)\n",
    "\n",
    "X_test = test_data['data']\n",
    "y_test = test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b7a6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping data\n",
    "data = X_test[11, :, :]\n",
    "data = data[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411f632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e6ac866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ddc86c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]),)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_test == 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cb296d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result: [[0.70629865]]\n"
     ]
    }
   ],
   "source": [
    "# Set input tensor to the interpreter\n",
    "interpreter.set_tensor(input_details[0]['index'], data.astype(np.float32))\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor and post-process the results (example)\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Inference result:\", output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
