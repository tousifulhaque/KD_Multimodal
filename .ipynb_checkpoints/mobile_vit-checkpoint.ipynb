{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60296eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import math\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fbe1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb57877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow imports \n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback, ModelCheckpoint\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Add, Dense, LayerNormalization,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, MultiHeadAttention, Layer, Embedding\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.metrics import Recall, Precision, AUC\n",
    "\n",
    "#local package import \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#local import \n",
    "from utils import sliding_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84567d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_act(mode = 'train', root_dir = 'dataset/SFDataset', data_type = 'watch_processed', new_len = 128, in_chan =3):\n",
    "    fall = os.path.join(os.getcwd() , f'{root_dir}/{data_type}/{mode}/**/Fall/***.csv')\n",
    "    adl = os.path.join(os.getcwd(), f'{root_dir}/{data_type}/{mode}/**/ADL/***.csv')\n",
    "    fall_files = glob.glob(fall)\n",
    "    adl_files = glob.glob(adl)\n",
    "    all_file_path = fall_files + adl_files\n",
    "    samples = len(all_file_path)\n",
    "    dataset = np.zeros((1,new_len, in_chan))\n",
    "    labels = []\n",
    "    fall_pattern = re.compile(\"Fall\")\n",
    "    \n",
    "    for file_path in all_file_path:\n",
    "        label = None\n",
    "        if fall_pattern.search(file_path):\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        if not df.empty:\n",
    "            df = df.loc[:,'DataCollection__w_accelerometer_x':'DataCollection__w_accelerometer_z']\n",
    "            trial = df.to_numpy()\n",
    "            act_len = trial.shape[0]\n",
    "            channel = trial.shape[1]\n",
    "            interpolated_data = interpolate(new_len, act_len, channel, trial)\n",
    "            dataset = np.concatenate((dataset,interpolated_data), axis = 0)\n",
    "            labels.append(label)\n",
    "    return tf.convert_to_tensor(dataset[1:, :, :]), tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4c65ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset , labels = processing_act(mode = 'val')\n",
    "np.savez('dataset/SFDataset/val',data = dataset, labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "aebf92c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(38,), dtype=int32, numpy=\n",
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f98fea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(mode = 'train', root_dir = 'dataset/SmartFall',data_type = 'phone&watch', new_len = 128, in_chan = 3):\n",
    "    fall = os.path.join(os.getcwd() , f'{root_dir}/{data_type}/{mode}/Fall/***.xlsx')\n",
    "    adl = os.path.join(os.getcwd(), f'{root_dir}/{data_type}/{mode}/ADL/***.xlsx')\n",
    "    fall_files = glob.glob(fall)\n",
    "    adl_files = glob.glob(adl)\n",
    "\n",
    "    all_file_path = fall_files + adl_files\n",
    "    samples = len(all_file_path)\n",
    "    dataset = np.zeros((1,new_len, in_chan))\n",
    "    \n",
    "    if len(all_file_path) == 0:\n",
    "        raise Exception('Data files not found')\n",
    " \n",
    "    trials_count = {}\n",
    "    fall_pattern = re.compile(\"Fall\")\n",
    "    trials = []\n",
    "    labels = []\n",
    "    length = []\n",
    "    #count = 0\n",
    "\n",
    "    for file_path in all_file_path:\n",
    "        print(file_path)\n",
    "        label = None\n",
    "        if fall_pattern.search(file_path):\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        #checking if the excel has 2 sheets or not\n",
    "        if len (pd.ExcelFile(file_path).sheet_names) == 2:\n",
    "                df = pd.read_excel(file_path, sheet_name=-1)\n",
    "                df = df.iloc[:, 12:15]\n",
    "                null_col = df[df.isnull().any(axis = 1)].index.to_list()\n",
    "                \n",
    "                if len(null_col) % 10 != 0  :\n",
    "                    print(f'{file_path} trimmed file contains {len(null_col)} of null rows')\n",
    "                    continue\n",
    "                elif len(null_col) == 0:\n",
    "                    trial = df.to_numpy()\n",
    "                    act_len = trial.shape[0]\n",
    "                    channel = trial.shape[1]\n",
    "                    interpolated_data = interpolate(new_len, act_len, channel, trial)\n",
    "                    dataset = np.concatenate((dataset,interpolated_data), axis = 0)\n",
    "                    labels.append(label)\n",
    "\n",
    "                \n",
    "                else:\n",
    "                    #raise Exception(f'{file_path} trimmed file contains {len(null_col)} of null rows')\n",
    "                    #calculating how many null segments we have \n",
    "                    null_col = df[df.isnull().any(axis = 1)].index.to_list()\n",
    "                    print(null_col)\n",
    "                    null_seg = len(null_col)//10\n",
    "\n",
    "\n",
    "                    trial_start_lst = null_col[9::10]\n",
    "                    trial_end_lst = null_col[10::10]\n",
    "\n",
    "                    for i in range(len(null_col)//10 + 1):\n",
    "                        #trials_count[label] = trials_count.get(label , 0) + 1\n",
    "                        trial = None\n",
    "                        if i == 0 :\n",
    "\n",
    "                            #trial = df.iloc[0:null_col[1]-1, 3:6]\n",
    "                            trial = df.iloc[0:null_col[1]-1, :]\n",
    "                        elif i == null_seg :\n",
    "                            #trial = df.iloc[trial_start_lst[-1]+1:, 3:6]\n",
    "                            trial = df.iloc[trial_start_lst[-1]+1:, :]\n",
    "                        else: \n",
    "                            trial_end = trial_end_lst[i-1]\n",
    "                            trial_start = trial_start_lst[i-1] + 1\n",
    "                            #trial = df.iloc[trial_start : trial_end-1 , 3:6]\n",
    "                            trial = df.iloc[trial_start : trial_end-1, : ]\n",
    "                            trial.dropna(inplace = True)\n",
    "\n",
    "                        #trial = tf.convert_to_tensor(trial.values, dtype = tf.float32)\n",
    "                        act_len = trial.shape[0]\n",
    "                        channel = trial.shape[1]\n",
    "                        trial = trial.to_numpy()\n",
    "                        if trial.shape[0] == 0:\n",
    "                            continue\n",
    "\n",
    "                        else:\n",
    "                            interpolated_data = interpolate(new_len, act_len, channel, trial)\n",
    "                            dataset = np.concatenate((dataset,interpolated_data), axis = 0)\n",
    "                            labels.append(label)\n",
    "\n",
    "        else:\n",
    "            raise Exception(f'{file_path} doesnt have trimmed data')\n",
    "        \n",
    "    return tf.convert_to_tensor(dataset[1:, :, :]), tf.convert_to_tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fd857582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(new_len, old_len, channel, data):\n",
    "    x = np.linspace(1, old_len, num = new_len)\n",
    "    xp = np.linspace(1, old_len, num = old_len)\n",
    "    interpolated_data = np.zeros((1, new_len, channel))\n",
    "    \n",
    "    for idx in range(channel):\n",
    "        yp = data[:, idx]\n",
    "        axis_interpolated = np.interp(x, xp, yp)\n",
    "        interpolated_data[0,:, idx] = axis_interpolated\n",
    "    \n",
    "    return interpolated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77678c42",
   "metadata": {},
   "source": [
    "### Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a133251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1_Score(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.precision_fn = Precision(thresholds=0.5)\n",
    "        self.recall_fn = Recall(thresholds=0.5)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        # since f1 is a variable, we use assign\n",
    "        self.f1.assign(2 * ((p * r) / (p + r + 1e-6)))\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        # we also need to reset the state of the precision and recall objects\n",
    "        self.precision_fn.reset_states()\n",
    "        self.recall_fn.reset_states()\n",
    "        self.f1.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9806ad",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b90978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_schedule(base_lr, total_steps, warmup_steps ):\n",
    "    def step_fn(epoch):\n",
    "        lr = base_lr \n",
    "        progress = (epoch - warmup_steps) / float(total_steps -  warmup_steps)\n",
    "\n",
    "        progress = tf.clip_by_value(progress, 0.0, 1.0)\n",
    "\n",
    "        lr = lr * 0.5 * (1.0 + tf.cos(math.pi * progress))\n",
    "        \n",
    "        if warmup_steps:\n",
    "            lr = lr * tf.minimum(1.0 , epoch/warmup_steps)\n",
    "        \n",
    "        return lr\n",
    "    \n",
    "\n",
    "    return step_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea991f",
   "metadata": {},
   "source": [
    "### Sliding Data into Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c078e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embedding(seq_len,d_model, n = 10000):\n",
    "    P = np.zeros((seq_len, d_model))\n",
    "    for k in range(seq_len):\n",
    "        for i in np.arange(int(d_model/2)):\n",
    "            denominator = np.power(n, 2*i/d_model)\n",
    "            P[k, 2*i] = np.sin(k/denominator)\n",
    "            P[k, 2*i + 1] = np.cos(k/denominator)\n",
    "    P = P[np.newaxis, : ,:]\n",
    "    return tf.Variable(P,trainable = False ,dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afdd83b",
   "metadata": {},
   "source": [
    "### Plot positional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1917e2ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'postional_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      3\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mi)\n\u001b[0;32m----> 4\u001b[0m     matrix \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mpostional_embedding\u001b[49m, (\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m))\n\u001b[1;32m      5\u001b[0m     cax \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mmatshow(matrix)\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgcf()\u001b[38;5;241m.\u001b[39mcolorbar(cax)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'postional_embedding' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "for i in range(2):\n",
    "    ax = plt.subplot(1, 2, 1+i)\n",
    "    matrix = tf.reshape(postional_embedding, (512, 256))\n",
    "    cax = ax.matshow(matrix)\n",
    "    plt.gcf().colorbar(cax)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d072c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, embed_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate, length, channel):\n",
    "    \n",
    "    #attention_layer\n",
    "    y = LayerNormalization(epsilon = 1e-6)(x)\n",
    "    y = MultiHeadAttention(num_heads = num_heads,key_dim = embed_dim,dropout = attention_dropout_rate, kernel_initializer = TruncatedNormal(stddev = 0.02))(query = x,value = x,key = x,training = True)\n",
    "    y = Dropout(rate = dropout_rate)(y)\n",
    "    y = Add()([x,y])\n",
    "    \n",
    "    #mlp_layer\n",
    "    y = LayerNormalization(epsilon = 1e-6)(x)\n",
    "    y = Dense(units = mlp_dim, kernel_initializer = TruncatedNormal(stddev = 0.02))(y)\n",
    "    y = Dropout(rate = dropout_rate)(y)\n",
    "    y = Dense(units = embed_dim, kernel_initializer = TruncatedNormal(stddev = 0.02))(y)\n",
    "    y = Dropout(rate = dropout_rate)(y)\n",
    "    y = Add()([x, y])\n",
    "    \n",
    "    return y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "386f52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(length, channels,num_layers, embed_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate):\n",
    "    \n",
    "    #initial normalization\n",
    "    pos_embed = get_positional_embedding(length, embed_dim)\n",
    "    inputs= keras.Input(shape = (length, channels))\n",
    "    x = Dense(embed_dim)(inputs)\n",
    "    #x = Normalization()(inputs)\n",
    "    x = x + pos_embed\n",
    "    #stacking encoder layers\n",
    "    for _ in range(num_layers):\n",
    "        x = encoder(x,embed_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate, length,channels)\n",
    "    x = LayerNormalization(epsilon=1e-5)(x)\n",
    "    \n",
    "    #pooling\n",
    "    x = GlobalAveragePooling1D(data_format = 'channels_first')(x)\n",
    "    \n",
    "    #output\n",
    "    output = Dense(1, kernel_initializer=\"zeros\", activation = 'sigmoid')(x)\n",
    "    \n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4e47042",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  'epochs': 50,\n",
    "  'length':128,\n",
    "  'channel':3,\n",
    "  'num_layers':  2,\n",
    "  'embed_layer_size': 32,\n",
    "  'global_clipnorm' : 3.0,\n",
    "  'fc_layer_size': 128,\n",
    "  'num_heads': 4,\n",
    "  'dropout': 0.1,\n",
    "  'attention_dropout': 0.1,\n",
    "  'optimizer': 'adam',\n",
    "  'amsgrad': False,\n",
    "  'label_smoothing': 0.1,\n",
    "  'learning_rate': 1e-3,\n",
    "  #'weight_decay': {\n",
    "  #    'values': [2.5e-4, 1e-4, 5e-5, 1e-5]\n",
    "  'warmup_steps': 5,\n",
    "  'batch_size': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79000de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "model = transformer(length = config['length'],\n",
    "        channels=config['channel'],\n",
    "        num_heads=config['num_heads'],\n",
    "        dropout_rate = config['dropout'],\n",
    "        attention_dropout_rate = config['attention_dropout'],\n",
    "        embed_dim =config['embed_layer_size'],\n",
    "        mlp_dim = config['fc_layer_size'], \n",
    "        num_layers = config['num_layers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb6c0e",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af639e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(15982, 50)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = os.path.join(os.getcwd(), 'dataset/new_watch_data_processed/watch_train.csv')\n",
    "val_dataset_path = os.path.join(os.getcwd(), 'dataset/new_watch_data_processed/watch_val.csv')\n",
    "window_size = 50\n",
    "#processing data \n",
    "train_dataframe = pd.read_csv(train_dataset_path)\n",
    "dataset = train_dataframe[['w_accelerometer_x', 'w_accelerometer_y', 'w_accelerometer_z']].to_numpy()\n",
    "labels = train_dataframe['outcome'].to_numpy()\n",
    "dataset, labels = sliding_window(dataset, labels, window_size - 1,dataset.shape[0],window_size,5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efb04fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79955,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3873423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79955, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f75b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading train dataset\n",
    "train_data = np.load(train_dataset_path)\n",
    "X_train = train_data['data']\n",
    "y_train = train_data['labels']\n",
    "\n",
    "#loading val dataset\n",
    "val_data = np.load(val_dataset_path)\n",
    "X_val = val_data[ 'data']\n",
    "y_val = val_data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca3eda",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa43285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer tf.__operators__.add was passed non-JSON-serializable arguments. Arguments had types: {'y': <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>, 'name': <class 'NoneType'>}. They cannot be serialized out when saving the model.\n",
      "Epoch 1/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.6931 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5000 - f1_score: 0.0000e+00\n",
      "Epoch 1: val_recall improved from -inf to 0.00000, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "44/44 [==============================] - 6s 106ms/step - loss: 0.6931 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5000 - f1_score: 0.0000e+00 - val_loss: 0.6931 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.5000 - val_f1_score: 0.0000e+00 - lr: 0.0000e+00\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.6928 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5059 - f1_score: 0.0000e+00\n",
      "Epoch 2: val_recall did not improve from 0.00000\n",
      "44/44 [==============================] - 4s 81ms/step - loss: 0.6928 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5059 - f1_score: 0.0000e+00 - val_loss: 0.6922 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.9250 - val_f1_score: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.6882 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5432 - f1_score: 0.0000e+00\n",
      "Epoch 3: val_recall did not improve from 0.00000\n",
      "44/44 [==============================] - 4s 85ms/step - loss: 0.6882 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.5432 - f1_score: 0.0000e+00 - val_loss: 0.6822 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 0.9861 - val_f1_score: 0.0000e+00 - lr: 4.0000e-04\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.6687 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6263 - f1_score: 0.0000e+00\n",
      "Epoch 4: val_recall did not improve from 0.00000\n",
      "44/44 [==============================] - 4s 87ms/step - loss: 0.6687 - recall: 0.0000e+00 - precision: 0.0000e+00 - auc: 0.6263 - f1_score: 0.0000e+00 - val_loss: 0.6273 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_auc: 1.0000 - val_f1_score: 0.0000e+00 - lr: 6.0000e-04\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.6375 - recall: 0.0662 - precision: 0.2571 - auc: 0.7210 - f1_score: 0.1053\n",
      "Epoch 5: val_recall improved from 0.00000 to 0.72222, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "44/44 [==============================] - 4s 89ms/step - loss: 0.6375 - recall: 0.0662 - precision: 0.2571 - auc: 0.7210 - f1_score: 0.1053 - val_loss: 0.5466 - val_recall: 0.7222 - val_precision: 1.0000 - val_auc: 1.0000 - val_f1_score: 0.8387 - lr: 8.0000e-04\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.6108 - recall: 0.3382 - precision: 0.5897 - auc: 0.7452 - f1_score: 0.4299\n",
      "Epoch 6: val_recall did not improve from 0.72222\n",
      "44/44 [==============================] - 4s 84ms/step - loss: 0.6108 - recall: 0.3382 - precision: 0.5897 - auc: 0.7452 - f1_score: 0.4299 - val_loss: 0.6006 - val_recall: 0.1667 - val_precision: 1.0000 - val_auc: 0.8944 - val_f1_score: 0.2857 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.6103 - recall: 0.3897 - precision: 0.6235 - auc: 0.7528 - f1_score: 0.4796\n",
      "Epoch 7: val_recall did not improve from 0.72222\n",
      "44/44 [==============================] - 4s 85ms/step - loss: 0.6103 - recall: 0.3897 - precision: 0.6235 - auc: 0.7528 - f1_score: 0.4796 - val_loss: 0.5114 - val_recall: 0.6111 - val_precision: 1.0000 - val_auc: 0.9944 - val_f1_score: 0.7586 - lr: 9.9878e-04\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5710 - recall: 0.5000 - precision: 0.7158 - auc: 0.8093 - f1_score: 0.5887\n",
      "Epoch 8: val_recall did not improve from 0.72222\n",
      "44/44 [==============================] - 4s 84ms/step - loss: 0.5710 - recall: 0.5000 - precision: 0.7158 - auc: 0.8093 - f1_score: 0.5887 - val_loss: 0.5006 - val_recall: 0.7222 - val_precision: 0.9286 - val_auc: 0.9694 - val_f1_score: 0.8125 - lr: 9.9513e-04\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5686 - recall: 0.5882 - precision: 0.7339 - auc: 0.8078 - f1_score: 0.6531\n",
      "Epoch 9: val_recall did not improve from 0.72222\n",
      "44/44 [==============================] - 4s 85ms/step - loss: 0.5686 - recall: 0.5882 - precision: 0.7339 - auc: 0.8078 - f1_score: 0.6531 - val_loss: 0.4640 - val_recall: 0.7222 - val_precision: 1.0000 - val_auc: 0.9778 - val_f1_score: 0.8387 - lr: 9.8907e-04\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5489 - recall: 0.6103 - precision: 0.7545 - auc: 0.8295 - f1_score: 0.6748\n",
      "Epoch 10: val_recall improved from 0.72222 to 0.88889, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "44/44 [==============================] - 4s 86ms/step - loss: 0.5489 - recall: 0.6103 - precision: 0.7545 - auc: 0.8295 - f1_score: 0.6748 - val_loss: 0.4210 - val_recall: 0.8889 - val_precision: 0.9412 - val_auc: 0.9806 - val_f1_score: 0.9143 - lr: 9.8063e-04\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5527 - recall: 0.6397 - precision: 0.7373 - auc: 0.8242 - f1_score: 0.6850\n",
      "Epoch 11: val_recall improved from 0.88889 to 0.94444, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "44/44 [==============================] - 4s 86ms/step - loss: 0.5527 - recall: 0.6397 - precision: 0.7373 - auc: 0.8242 - f1_score: 0.6850 - val_loss: 0.4106 - val_recall: 0.9444 - val_precision: 0.8500 - val_auc: 0.9750 - val_f1_score: 0.8947 - lr: 9.6985e-04\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5282 - recall: 0.6471 - precision: 0.7719 - auc: 0.8514 - f1_score: 0.7040\n",
      "Epoch 12: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 86ms/step - loss: 0.5282 - recall: 0.6471 - precision: 0.7719 - auc: 0.8514 - f1_score: 0.7040 - val_loss: 0.3796 - val_recall: 0.8889 - val_precision: 1.0000 - val_auc: 0.9875 - val_f1_score: 0.9412 - lr: 9.5677e-04\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5276 - recall: 0.6397 - precision: 0.7632 - auc: 0.8481 - f1_score: 0.6960\n",
      "Epoch 13: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 87ms/step - loss: 0.5276 - recall: 0.6397 - precision: 0.7632 - auc: 0.8481 - f1_score: 0.6960 - val_loss: 0.4025 - val_recall: 0.7222 - val_precision: 1.0000 - val_auc: 0.9778 - val_f1_score: 0.8387 - lr: 9.4147e-04\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5282 - recall: 0.6176 - precision: 0.7706 - auc: 0.8531 - f1_score: 0.6857\n",
      "Epoch 14: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 85ms/step - loss: 0.5282 - recall: 0.6176 - precision: 0.7706 - auc: 0.8531 - f1_score: 0.6857 - val_loss: 0.3644 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9875 - val_f1_score: 0.9714 - lr: 9.2402e-04\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5162 - recall: 0.6397 - precision: 0.7565 - auc: 0.8634 - f1_score: 0.6932\n",
      "Epoch 15: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 89ms/step - loss: 0.5162 - recall: 0.6397 - precision: 0.7565 - auc: 0.8634 - f1_score: 0.6932 - val_loss: 0.3498 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 9.0451e-04\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5045 - recall: 0.6691 - precision: 0.7778 - auc: 0.8713 - f1_score: 0.7194\n",
      "Epoch 16: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 87ms/step - loss: 0.5045 - recall: 0.6691 - precision: 0.7778 - auc: 0.8713 - f1_score: 0.7194 - val_loss: 0.3384 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 8.8302e-04\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.5120 - recall: 0.6765 - precision: 0.7541 - auc: 0.8693 - f1_score: 0.7132\n",
      "Epoch 17: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 85ms/step - loss: 0.5120 - recall: 0.6765 - precision: 0.7541 - auc: 0.8693 - f1_score: 0.7132 - val_loss: 0.3486 - val_recall: 0.9444 - val_precision: 0.9444 - val_auc: 0.9861 - val_f1_score: 0.9444 - lr: 8.5967e-04\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4961 - recall: 0.6985 - precision: 0.7917 - auc: 0.8801 - f1_score: 0.7422\n",
      "Epoch 18: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 86ms/step - loss: 0.4961 - recall: 0.6985 - precision: 0.7917 - auc: 0.8801 - f1_score: 0.7422 - val_loss: 0.3482 - val_recall: 0.8889 - val_precision: 1.0000 - val_auc: 0.9889 - val_f1_score: 0.9412 - lr: 8.3457e-04\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4927 - recall: 0.6471 - precision: 0.8073 - auc: 0.8856 - f1_score: 0.7184\n",
      "Epoch 19: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 86ms/step - loss: 0.4927 - recall: 0.6471 - precision: 0.8073 - auc: 0.8856 - f1_score: 0.7184 - val_loss: 0.3267 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 8.0783e-04\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4908 - recall: 0.6912 - precision: 0.7581 - auc: 0.8839 - f1_score: 0.7231\n",
      "Epoch 20: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 87ms/step - loss: 0.4908 - recall: 0.6912 - precision: 0.7581 - auc: 0.8839 - f1_score: 0.7231 - val_loss: 0.3477 - val_recall: 0.8889 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9412 - lr: 7.7960e-04\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4939 - recall: 0.6544 - precision: 0.8318 - auc: 0.8850 - f1_score: 0.7325\n",
      "Epoch 21: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 86ms/step - loss: 0.4939 - recall: 0.6544 - precision: 0.8318 - auc: 0.8850 - f1_score: 0.7325 - val_loss: 0.3226 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 7.5000e-04\n",
      "Epoch 22/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4884 - recall: 0.6912 - precision: 0.7705 - auc: 0.8887 - f1_score: 0.7287\n",
      "Epoch 22: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 84ms/step - loss: 0.4884 - recall: 0.6912 - precision: 0.7705 - auc: 0.8887 - f1_score: 0.7287 - val_loss: 0.3190 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 7.1919e-04\n",
      "Epoch 23/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4826 - recall: 0.6985 - precision: 0.7983 - auc: 0.8932 - f1_score: 0.7451\n",
      "Epoch 23: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 85ms/step - loss: 0.4826 - recall: 0.6985 - precision: 0.7983 - auc: 0.8932 - f1_score: 0.7451 - val_loss: 0.3130 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9944 - val_f1_score: 0.9714 - lr: 6.8730e-04\n",
      "Epoch 24/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4788 - recall: 0.7279 - precision: 0.8049 - auc: 0.8932 - f1_score: 0.7645\n",
      "Epoch 24: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 87ms/step - loss: 0.4788 - recall: 0.7279 - precision: 0.8049 - auc: 0.8932 - f1_score: 0.7645 - val_loss: 0.3072 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 6.5451e-04\n",
      "Epoch 25/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4792 - recall: 0.7059 - precision: 0.8000 - auc: 0.8943 - f1_score: 0.7500\n",
      "Epoch 25: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4792 - recall: 0.7059 - precision: 0.8000 - auc: 0.8943 - f1_score: 0.7500 - val_loss: 0.3110 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 6.2096e-04\n",
      "Epoch 26/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4747 - recall: 0.7206 - precision: 0.7717 - auc: 0.8977 - f1_score: 0.7452\n",
      "Epoch 26: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4747 - recall: 0.7206 - precision: 0.7717 - auc: 0.8977 - f1_score: 0.7452 - val_loss: 0.3108 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 5.8682e-04\n",
      "Epoch 27/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4724 - recall: 0.7132 - precision: 0.7951 - auc: 0.8993 - f1_score: 0.7519\n",
      "Epoch 27: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 90ms/step - loss: 0.4724 - recall: 0.7132 - precision: 0.7951 - auc: 0.8993 - f1_score: 0.7519 - val_loss: 0.3239 - val_recall: 0.8889 - val_precision: 1.0000 - val_auc: 0.9944 - val_f1_score: 0.9412 - lr: 5.5226e-04\n",
      "Epoch 28/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4652 - recall: 0.7206 - precision: 0.8376 - auc: 0.9058 - f1_score: 0.7747\n",
      "Epoch 28: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 87ms/step - loss: 0.4652 - recall: 0.7206 - precision: 0.8376 - auc: 0.9058 - f1_score: 0.7747 - val_loss: 0.3004 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9944 - val_f1_score: 0.9714 - lr: 5.1745e-04\n",
      "Epoch 29/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4663 - recall: 0.7279 - precision: 0.8115 - auc: 0.9061 - f1_score: 0.7674\n",
      "Epoch 29: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 89ms/step - loss: 0.4663 - recall: 0.7279 - precision: 0.8115 - auc: 0.9061 - f1_score: 0.7674 - val_loss: 0.2985 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 4.8255e-04\n",
      "Epoch 30/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4667 - recall: 0.7206 - precision: 0.8167 - auc: 0.9048 - f1_score: 0.7656\n",
      "Epoch 30: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4667 - recall: 0.7206 - precision: 0.8167 - auc: 0.9048 - f1_score: 0.7656 - val_loss: 0.3103 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9944 - val_f1_score: 0.9714 - lr: 4.4774e-04\n",
      "Epoch 31/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4638 - recall: 0.7721 - precision: 0.8140 - auc: 0.9056 - f1_score: 0.7925\n",
      "Epoch 31: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 89ms/step - loss: 0.4638 - recall: 0.7721 - precision: 0.8140 - auc: 0.9056 - f1_score: 0.7925 - val_loss: 0.2987 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 4.1318e-04\n",
      "Epoch 32/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4586 - recall: 0.7206 - precision: 0.8376 - auc: 0.9117 - f1_score: 0.7747\n",
      "Epoch 32: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4586 - recall: 0.7206 - precision: 0.8376 - auc: 0.9117 - f1_score: 0.7747 - val_loss: 0.2993 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 3.7904e-04\n",
      "Epoch 33/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4611 - recall: 0.7721 - precision: 0.8203 - auc: 0.9073 - f1_score: 0.7955\n",
      "Epoch 33: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 89ms/step - loss: 0.4611 - recall: 0.7721 - precision: 0.8203 - auc: 0.9073 - f1_score: 0.7955 - val_loss: 0.3070 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9931 - val_f1_score: 0.9714 - lr: 3.4549e-04\n",
      "Epoch 34/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4524 - recall: 0.7206 - precision: 0.8522 - auc: 0.9158 - f1_score: 0.7809\n",
      "Epoch 34: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 89ms/step - loss: 0.4524 - recall: 0.7206 - precision: 0.8522 - auc: 0.9158 - f1_score: 0.7809 - val_loss: 0.2994 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 3.1270e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4507 - recall: 0.7574 - precision: 0.8443 - auc: 0.9157 - f1_score: 0.7984\n",
      "Epoch 35: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4507 - recall: 0.7574 - precision: 0.8443 - auc: 0.9157 - f1_score: 0.7984 - val_loss: 0.3002 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 2.8081e-04\n",
      "Epoch 36/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4483 - recall: 0.7206 - precision: 0.8522 - auc: 0.9182 - f1_score: 0.7809\n",
      "Epoch 36: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4483 - recall: 0.7206 - precision: 0.8522 - auc: 0.9182 - f1_score: 0.7809 - val_loss: 0.3012 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9931 - val_f1_score: 0.9714 - lr: 2.5000e-04\n",
      "Epoch 37/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4478 - recall: 0.7647 - precision: 0.8595 - auc: 0.9167 - f1_score: 0.8093\n",
      "Epoch 37: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4478 - recall: 0.7647 - precision: 0.8595 - auc: 0.9167 - f1_score: 0.8093 - val_loss: 0.3025 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9944 - val_f1_score: 0.9714 - lr: 2.2040e-04\n",
      "Epoch 38/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4462 - recall: 0.7574 - precision: 0.8583 - auc: 0.9176 - f1_score: 0.8047\n",
      "Epoch 38: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 86ms/step - loss: 0.4462 - recall: 0.7574 - precision: 0.8583 - auc: 0.9176 - f1_score: 0.8047 - val_loss: 0.3018 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9944 - val_f1_score: 0.9714 - lr: 1.9217e-04\n",
      "Epoch 39/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4446 - recall: 0.7426 - precision: 0.8632 - auc: 0.9223 - f1_score: 0.7984\n",
      "Epoch 39: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 90ms/step - loss: 0.4446 - recall: 0.7426 - precision: 0.8632 - auc: 0.9223 - f1_score: 0.7984 - val_loss: 0.2943 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 1.6543e-04\n",
      "Epoch 40/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4439 - recall: 0.7868 - precision: 0.8168 - auc: 0.9184 - f1_score: 0.8015\n",
      "Epoch 40: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 89ms/step - loss: 0.4439 - recall: 0.7868 - precision: 0.8168 - auc: 0.9184 - f1_score: 0.8015 - val_loss: 0.2939 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 1.4033e-04\n",
      "Epoch 41/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4415 - recall: 0.7574 - precision: 0.8512 - auc: 0.9218 - f1_score: 0.8016\n",
      "Epoch 41: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 90ms/step - loss: 0.4415 - recall: 0.7574 - precision: 0.8512 - auc: 0.9218 - f1_score: 0.8016 - val_loss: 0.2983 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9931 - val_f1_score: 0.9714 - lr: 1.1698e-04\n",
      "Epoch 42/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4393 - recall: 0.7647 - precision: 0.8667 - auc: 0.9238 - f1_score: 0.8125\n",
      "Epoch 42: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4393 - recall: 0.7647 - precision: 0.8667 - auc: 0.9238 - f1_score: 0.8125 - val_loss: 0.2989 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9944 - val_f1_score: 0.9714 - lr: 9.5492e-05\n",
      "Epoch 43/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4394 - recall: 0.7794 - precision: 0.8548 - auc: 0.9221 - f1_score: 0.8154\n",
      "Epoch 43: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4394 - recall: 0.7794 - precision: 0.8548 - auc: 0.9221 - f1_score: 0.8154 - val_loss: 0.2945 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 7.5976e-05\n",
      "Epoch 44/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4391 - recall: 0.7794 - precision: 0.8618 - auc: 0.9228 - f1_score: 0.8185\n",
      "Epoch 44: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 90ms/step - loss: 0.4391 - recall: 0.7794 - precision: 0.8618 - auc: 0.9228 - f1_score: 0.8185 - val_loss: 0.2968 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 5.8526e-05\n",
      "Epoch 45/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4365 - recall: 0.7794 - precision: 0.8618 - auc: 0.9248 - f1_score: 0.8185\n",
      "Epoch 45: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.4365 - recall: 0.7794 - precision: 0.8618 - auc: 0.9248 - f1_score: 0.8185 - val_loss: 0.2966 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 4.3227e-05\n",
      "Epoch 46/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4364 - recall: 0.7574 - precision: 0.8583 - auc: 0.9247 - f1_score: 0.8047\n",
      "Epoch 46: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 89ms/step - loss: 0.4364 - recall: 0.7574 - precision: 0.8583 - auc: 0.9247 - f1_score: 0.8047 - val_loss: 0.2954 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 3.0154e-05\n",
      "Epoch 47/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4369 - recall: 0.7868 - precision: 0.8629 - auc: 0.9243 - f1_score: 0.8231\n",
      "Epoch 47: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 88ms/step - loss: 0.4369 - recall: 0.7868 - precision: 0.8629 - auc: 0.9243 - f1_score: 0.8231 - val_loss: 0.2959 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 1.9369e-05\n",
      "Epoch 48/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4362 - recall: 0.7794 - precision: 0.8618 - auc: 0.9250 - f1_score: 0.8185\n",
      "Epoch 48: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 90ms/step - loss: 0.4362 - recall: 0.7794 - precision: 0.8618 - auc: 0.9250 - f1_score: 0.8185 - val_loss: 0.2958 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 1.0926e-05\n",
      "Epoch 49/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4367 - recall: 0.7868 - precision: 0.8629 - auc: 0.9247 - f1_score: 0.8231\n",
      "Epoch 49: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.4367 - recall: 0.7868 - precision: 0.8629 - auc: 0.9247 - f1_score: 0.8231 - val_loss: 0.2958 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 4.8659e-06\n",
      "Epoch 50/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.4351 - recall: 0.7721 - precision: 0.8607 - auc: 0.9251 - f1_score: 0.8140\n",
      "Epoch 50: val_recall did not improve from 0.94444\n",
      "44/44 [==============================] - 4s 91ms/step - loss: 0.4351 - recall: 0.7721 - precision: 0.8607 - auc: 0.9251 - f1_score: 0.8140 - val_loss: 0.2958 - val_recall: 0.9444 - val_precision: 1.0000 - val_auc: 0.9917 - val_f1_score: 0.9714 - lr: 1.2180e-06\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "      loss= BinaryCrossentropy(label_smoothing=config['label_smoothing']),\n",
    "      optimizer=Adam(\n",
    "          global_clipnorm=config['global_clipnorm'],\n",
    "          amsgrad=config['amsgrad'],\n",
    "      ),\n",
    "      metrics=[Recall(), Precision() , AUC(), F1_Score()],\n",
    "    )\n",
    "checkpoint_filepath = os.path.join(os.getcwd(), 'tmp/weights.ckpt')\n",
    "model_checkpoint = ModelCheckpoint(filepath = checkpoint_filepath, \n",
    "                                      save_weights_only = True, \n",
    "                                      monitor = 'val_recall', \n",
    "                                      mode = 'max', \n",
    "                                      save_best_only = True, \n",
    "                                      verbose = True)\n",
    "log_dir = \"logs/\"  # Specify the directory where TensorBoard logs will be saved\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history = model.fit(\n",
    "      X_train,\n",
    "      y_train,\n",
    "      batch_size=config['batch_size'],\n",
    "      epochs=config['epochs'],\n",
    "      validation_data=(X_val, y_val),\n",
    "      shuffle = True,\n",
    "      callbacks=[\n",
    "        LearningRateScheduler(cosine_schedule(base_lr=config['learning_rate'], total_steps=config['epochs'], warmup_steps=config['warmup_steps'])),\n",
    "        #EarlyStopping(monitor=\"loss\", mode='min', min_delta=0.001, patience=5),\n",
    "        model_checkpoint, tensorboard_callback\n",
    "      ],\n",
    "      verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "07f287b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926709b6",
   "metadata": {},
   "source": [
    "### Converting to tflite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c821a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fae1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding special ops\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops. <-- Add this line\n",
    "]\n",
    "converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.allow_custom_ops=True\n",
    "converter.experimental_new_converter =True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "#converting to tflite \n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "884a0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the tflite model to a file \n",
    "with open('model_watch.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37932237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using interpreter to test\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model_watch.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa0ad02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "test_dataset_path = os.path.join(os.getcwd(), 'dataset/SFDataset/test.npz')\n",
    "test_data = np.load(test_dataset_path)\n",
    "\n",
    "X_test = test_data['data']\n",
    "y_test = test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b7a6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping data\n",
    "data = X_test[11, :, :]\n",
    "data = data[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411f632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e6ac866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ddc86c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]),)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_test == 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cb296d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result: [[0.70629865]]\n"
     ]
    }
   ],
   "source": [
    "# Set input tensor to the interpreter\n",
    "interpreter.set_tensor(input_details[0]['index'], data.astype(np.float32))\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor and post-process the results (example)\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Inference result:\", output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
