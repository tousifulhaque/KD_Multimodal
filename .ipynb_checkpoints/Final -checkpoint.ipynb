{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9dde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dad3b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # FATAL\n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f344b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  wandb_config import sweep_config\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow_addons.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, Callback\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Add, Dense, LayerNormalization, Normalization , Masking, GlobalAveragePooling1D, Conv1D, Dropout, MultiHeadAttention, Layer\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, Callback, ModelCheckpoint\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.metrics import Recall, Precision , AUC\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6467ce59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 234, done.\n",
      "Counting objects: 100% (234/234), done.\n",
      "Delta compression using up to 8 threads\n",
      "Compressing objects: 100% (227/227), done.\n",
      "Writing objects: 100% (227/227), 38.61 MiB | 2.18 MiB/s, done.\n",
      "Total 227 (delta 7), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (7/7), completed with 4 local objects.\u001b[K\n",
      "To https://github.com/tousifulhaque/KD_Multimodal.git\n",
      "   69039b8..61285e8  main -> main\n"
     ]
    }
   ],
   "source": [
    "# ! git add .\n",
    "# ! git commit -m \"Feat: New Dataset Generation\"\n",
    "! git push "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85329e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b7\u001b[?47h\u001b[>4;2m\u001b[?1h\u001b=\u001b[?2004h\u001b[?1004h\u001b[1;24r\u001b[?12h\u001b[?12l\u001b[22;2t\u001b[22;1t\u001b[29m\u001b[m\u001b[H\u001b[2J\u001b[?25l\u001b[24;1H\".gitignore\" 3L, 70B\u001b[2;1Hâ–½\u001b[6n\u001b[2;1H  \u001b[3;1H\u001bPzz\u001b\\\u001b[0%m\u001b[6n\u001b[3;1H           \u001b[1;1H\u001b[>c\u001b]10;?\u0007\u001b]11;?\u0007\u001b[1;1Hnew_dataset.npz\n",
      "KU-HAR_time_domain_subsamples_20750x300.csv\u001b[2;44H\u001b[K\u001b[3;1H/datasets\u001b[3;10H\u001b[K\u001b[4;1H\u001b[1m\u001b[34m~                                                                               \u001b[5;1H~                                                                               \u001b[6;1H~                                                                               \u001b[7;1H~                                                                               \u001b[8;1H~                                                                               \u001b[9;1H~                                                                               \u001b[10;1H~                                                                               \u001b[11;1H~                                                                               \u001b[12;1H~                                                                               \u001b[13;1H~                                                                               \u001b[14;1H~                                                                               \u001b[15;1H~                                                                               \u001b[16;1H~                                                                               \u001b[17;1H~                                                                               \u001b[18;1H~                                                                               \u001b[19;1H~                                                                               \u001b[20;1H~                                                                               \u001b[21;1H~                                                                               \u001b[22;1H~                                                                               \u001b[23;1H~                                                                               \u001b[1;1H\u001b[?25h\u001b[?25l\u001b[m\u001b[24;1HType  :qa  and press <Enter> to exit Vim\u0007\u001b[1;1H\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!vim .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7b941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0ba524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1_Score(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.precision_fn = Precision(thresholds=0.5)\n",
    "        self.recall_fn = Recall(thresholds=0.5)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        # since f1 is a variable, we use assign\n",
    "        self.f1.assign(2 * ((p * r) / (p + r + 1e-6)))\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        # we also need to reset the state of the precision and recall objects\n",
    "        self.precision_fn.reset_states()\n",
    "        self.recall_fn.reset_states()\n",
    "        self.f1.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83288736",
   "metadata": {},
   "source": [
    "## Lr Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff9b8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "# from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# class PrintLR(Callback):\n",
    "#     def on_epoch_end(self, epoch, logs = None):\n",
    "\n",
    "\n",
    "def cosine_schedule(base_lr, total_steps, warmup_steps ):\n",
    "    def step_fn(epoch):\n",
    "        lr = base_lr \n",
    "        progress = (epoch - warmup_steps) / float(total_steps -  warmup_steps)\n",
    "\n",
    "        progress = tf.clip_by_value(progress, 0.0, 1.0)\n",
    "\n",
    "        lr = lr * 0.5 * (1.0 + tf.cos(math.pi * progress))\n",
    "        \n",
    "        if warmup_steps:\n",
    "            lr = lr * tf.minimum(1.0 , epoch/warmup_steps)\n",
    "        \n",
    "        return lr\n",
    "    \n",
    "\n",
    "    return step_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388df218",
   "metadata": {},
   "source": [
    "## Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c02f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEmbedding(Layer):\n",
    "    def __init__(self, units,dropout_rate,  **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "\n",
    "        self.units = units\n",
    "        self.conv_1 = Conv1D(filters  = units, kernel_size = 1)\n",
    "        self.projection = Dense(units, kernel_initializer=TruncatedNormal(stddev=0.02))\n",
    "\n",
    "        self.dropout = Dropout(rate=dropout_rate)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(PositionalEmbedding, self).build(input_shape)\n",
    "\n",
    "        self.position = self.add_weight(\n",
    "            name=\"position\",\n",
    "            shape=(1, input_shape[1], self.units),\n",
    "            initializer=TruncatedNormal(stddev=0.02),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        x = self.projection(inputs)\n",
    "        # x = self.conv_1(inputs)\n",
    "        x = x + self.position\n",
    "        return self.dropout(x, training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756111d",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e956fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    def __init__(\n",
    "        self, embed_dim, mlp_dim, num_heads, dropout_rate,\n",
    "        attention_dropout_rate, **kwargs\n",
    "    ):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "        self.mha = MultiHeadAttention(\n",
    "            num_heads = num_heads,\n",
    "            key_dim = embed_dim,\n",
    "            dropout = attention_dropout_rate, \n",
    "            kernel_initializer = TruncatedNormal(stddev = 0.02)\n",
    "        )\n",
    "\n",
    "        self. dense_0 = Dense(\n",
    "            units = mlp_dim, \n",
    "            activation = \"gelu\", \n",
    "            kernel_initializer = TruncatedNormal(stddev = 0.02)\n",
    "        )\n",
    "\n",
    "        self.dense_1 = Dense(\n",
    "            units = embed_dim, \n",
    "            kernel_initializer = TruncatedNormal(stddev = 0.02)\n",
    "        )\n",
    "\n",
    "        self.conv_0 = Conv1D(filters = 4 , kernel_size = 1, activation = 'relu')\n",
    "        self.conv_1 = Conv1D(filters  = embed_dim, kernel_size = 1)\n",
    "\n",
    "        self.dropout_0 = Dropout(rate = dropout_rate)\n",
    "        self.dropout_1 = Dropout(rate = dropout_rate)\n",
    "\n",
    "        self.norm_0 = LayerNormalization(epsilon = 1e-6)\n",
    "        self.norm_1 = LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "        self.add_0 = Add()\n",
    "        self.add_1 = Add()\n",
    "    \n",
    "    def call(self, inputs, training , mask):\n",
    "\n",
    "\n",
    "        x = self.norm_0(inputs)\n",
    "        x = self.mha(\n",
    "            query = x, \n",
    "            value = x, \n",
    "            key = x,\n",
    "            attention_mask = mask,\n",
    "            training = training\n",
    "        ) #[batch_size, sequence_length, embed_dim][8, 500, 3]\n",
    "        x = self.dropout_0(x, training= training)\n",
    "        x = self.add_0([x, inputs])\n",
    "\n",
    "        #MLP block \n",
    "        y = self.norm_1(x)\n",
    "        y = self.conv_0(y) #[batch_size , sequence_length, neurons]\n",
    "#         y = self.dropout_1(y, training)\n",
    "        y = self.conv_1(y)#[batch_size , sequence_lenght, neurons]\n",
    "#         y = self.dropout_1(y, training)\n",
    "        \n",
    "\n",
    "        return self.add_1([x, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e6abf",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af2665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        embed_dim,\n",
    "        mlp_dim,\n",
    "        num_heads,\n",
    "        num_classes,\n",
    "        dropout_rate,\n",
    "        attention_dropout_rate,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "\n",
    "        # Input (normalization of RAW measurements)\n",
    "        self.input_norm = Normalization()\n",
    "        \n",
    "        #Making Layer\n",
    "        self.masking_layer = Masking(mask_value = 0.0)\n",
    "\n",
    "        # Input\n",
    "        self.pos_embs = PositionalEmbedding(embed_dim, dropout_rate)\n",
    "\n",
    "        # Encoder\n",
    "        self.e_layers = [\n",
    "            Encoder(embed_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "        # Output\n",
    "        self.norm = LayerNormalization(epsilon=1e-5)\n",
    "        self.pool = GlobalAveragePooling1D(data_format = 'channels_first')\n",
    "        self.dense_0 = Dense(mlp_dim, activation = 'relu')\n",
    "        self.final_layer = Dense(1, kernel_initializer=\"zeros\", activation = 'sigmoid')\n",
    "\n",
    "    def call(self, inputs, training = True):\n",
    "        expanded_input = tf.cast(tf.tile(tf.expand_dims(inputs, axis=-2), [1, 1, 500,1]), tf.float32)\n",
    "        self.masking_layer.build(expanded_input.shape)\n",
    "        mask = self.masking_layer.compute_mask(expanded_input)\n",
    "        x = self.input_norm(inputs) \n",
    "        x = self.pos_embs(x, training=training)\n",
    "        for layer in self.e_layers:\n",
    "            x = layer(x, training=training , mask = mask)\n",
    "        x = self.norm(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dense_0(x)\n",
    "\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380a929",
   "metadata": {},
   "source": [
    "## Train Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6cc2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "    config = {\n",
    "      'epochs': 50,\n",
    "      'num_layers':  3,\n",
    "      'embed_layer_size': 3,\n",
    "      'global_clipnorm' : 3.0,\n",
    "      'fc_layer_size': 256,\n",
    "      'num_heads': 2,\n",
    "      'dropout': 0.1,\n",
    "      'attention_dropout': 0.1,\n",
    "      'optimizer': 'adam',\n",
    "      'amsgrad': False,\n",
    "      'label_smoothing': 0.1,\n",
    "      'learning_rate': 1e-3,\n",
    "      #'weight_decay': {\n",
    "      #    'values': [2.5e-4, 1e-4, 5e-5, 1e-5]\n",
    "      'warmup_steps': 5,\n",
    "      'batch_size': 8}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "428f63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def create_model():\n",
    "\n",
    "\n",
    "    # config = wandb.config\n",
    "    \n",
    "    # Generate new model\n",
    "    model = Transformer(\n",
    "      num_layers=config['num_layers'],\n",
    "      embed_dim=config['embed_layer_size']\n",
    "      ,\n",
    "      mlp_dim=config['fc_layer_size'],\n",
    "      num_heads=config['num_heads'],\n",
    "      num_classes=2,\n",
    "      dropout_rate=config['dropout'],\n",
    "      attention_dropout_rate=config['attention_dropout'],\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    # adapt on training dataset - must be before model.compile !!!\n",
    "    model.input_norm.adapt(X_train, batch_size=config['batch_size'])\n",
    "    # print(model.input_norm.variables)\n",
    "\n",
    "    # Select optimizer\n",
    "    if config['optimizer'] == \"adam\":\n",
    "      optim = Adam(\n",
    "          global_clipnorm=config['global_clipnorm'],\n",
    "          amsgrad=config['amsgrad'],\n",
    "      )\n",
    "    # elif config.optimizer == \"adamw\":\n",
    "    #   optim = AdamW(\n",
    "    #       weight_decay=config.weight_decay,\n",
    "    #       amsgrad=config.amsgrad,\n",
    "    #       global_clipnorm=config.global_clipnorm,\n",
    "    #       exclude_from_weight_decay=[\"position\"]\n",
    "    #   )\n",
    "    else:\n",
    "      raise ValueError(\"The used optimizer is not in list of available\")\n",
    "\n",
    "    model.compile(\n",
    "      loss= BinaryCrossentropy(label_smoothing=config['label_smoothing']),\n",
    "      optimizer=optim,\n",
    "      metrics=[Recall(), Precision() , AUC(), F1_Score()],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8342ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model = create_model()\n",
    "    checkpoint_filepath = os.path.join(os.getcwd(), 'tmp/weights.ckpt')\n",
    "    model_checkpoint = ModelCheckpoint(filepath = checkpoint_filepath, \n",
    "                                      save_weights_only = True, \n",
    "                                      monitor = 'val_f1_score', \n",
    "                                      mode = 'max', \n",
    "                                      save_best_only = True, \n",
    "                                      verbose = True)\n",
    "\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "      X_train,\n",
    "      y_train,\n",
    "      batch_size=config['batch_size'],\n",
    "      epochs=config['epochs'],\n",
    "      validation_data=(X_val, y_val),\n",
    "      callbacks=[\n",
    "        LearningRateScheduler(cosine_schedule(base_lr=config['learning_rate'], total_steps=config['epochs'], warmup_steps=config['warmup_steps'])),\n",
    "        EarlyStopping(monitor=\"val_loss\", mode='min', min_delta=0.001, patience=5),\n",
    "        model_checkpoint\n",
    "      ],\n",
    "      verbose=1\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f06f53c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6931 - recall_2: 0.5650 - precision_2: 0.4973 - auc_1: 0.5000 - f1_score: 0.5290\n",
      "Epoch 1: val_f1_score improved from -inf to 0.68217, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 31s 338ms/step - loss: 0.6931 - recall_2: 0.5650 - precision_2: 0.4973 - auc_1: 0.5000 - f1_score: 0.5290 - val_loss: 0.6930 - val_recall_2: 0.7458 - val_precision_2: 0.6286 - val_auc_1: 0.5000 - val_f1_score: 0.6822 - lr: 2.0000e-04\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6911 - recall_2: 0.9215 - precision_2: 0.5535 - auc_1: 0.6215 - f1_score: 0.6916\n",
      "Epoch 2: val_f1_score improved from 0.68217 to 0.77941, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 26s 318ms/step - loss: 0.6911 - recall_2: 0.9215 - precision_2: 0.5535 - auc_1: 0.6215 - f1_score: 0.6916 - val_loss: 0.6864 - val_recall_2: 0.8983 - val_precision_2: 0.6883 - val_auc_1: 0.6945 - val_f1_score: 0.7794 - lr: 2.0000e-04\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6652 - recall_2: 0.8187 - precision_2: 0.6642 - auc_1: 0.7415 - f1_score: 0.7334\n",
      "Epoch 3: val_f1_score improved from 0.77941 to 0.78873, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 27s 331ms/step - loss: 0.6652 - recall_2: 0.8187 - precision_2: 0.6642 - auc_1: 0.7415 - f1_score: 0.7334 - val_loss: 0.6257 - val_recall_2: 0.9492 - val_precision_2: 0.6747 - val_auc_1: 0.8240 - val_f1_score: 0.7887 - lr: 2.0000e-04\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5926 - recall_2: 0.8671 - precision_2: 0.7104 - auc_1: 0.8122 - f1_score: 0.7810\n",
      "Epoch 4: val_f1_score improved from 0.78873 to 0.79137, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 27s 326ms/step - loss: 0.5926 - recall_2: 0.8671 - precision_2: 0.7104 - auc_1: 0.8122 - f1_score: 0.7810 - val_loss: 0.5506 - val_recall_2: 0.9322 - val_precision_2: 0.6875 - val_auc_1: 0.8686 - val_f1_score: 0.7914 - lr: 2.0000e-04\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5287 - recall_2: 0.8912 - precision_2: 0.7284 - auc_1: 0.8704 - f1_score: 0.8016\n",
      "Epoch 5: val_f1_score did not improve from 0.79137\n",
      "82/82 [==============================] - 27s 328ms/step - loss: 0.5287 - recall_2: 0.8912 - precision_2: 0.7284 - auc_1: 0.8704 - f1_score: 0.8016 - val_loss: 0.5140 - val_recall_2: 0.9492 - val_precision_2: 0.6747 - val_auc_1: 0.9031 - val_f1_score: 0.7887 - lr: 2.0000e-04\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5036 - recall_2: 0.8822 - precision_2: 0.7355 - auc_1: 0.8812 - f1_score: 0.8022\n",
      "Epoch 6: val_f1_score improved from 0.79137 to 0.84127, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 26s 319ms/step - loss: 0.5036 - recall_2: 0.8822 - precision_2: 0.7355 - auc_1: 0.8812 - f1_score: 0.8022 - val_loss: 0.4676 - val_recall_2: 0.8983 - val_precision_2: 0.7910 - val_auc_1: 0.9169 - val_f1_score: 0.8413 - lr: 2.0000e-04\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4818 - recall_2: 0.8792 - precision_2: 0.7618 - auc_1: 0.8973 - f1_score: 0.8163\n",
      "Epoch 7: val_f1_score did not improve from 0.84127\n",
      "82/82 [==============================] - 26s 318ms/step - loss: 0.4818 - recall_2: 0.8792 - precision_2: 0.7618 - auc_1: 0.8973 - f1_score: 0.8163 - val_loss: 0.4541 - val_recall_2: 0.9322 - val_precision_2: 0.7639 - val_auc_1: 0.9275 - val_f1_score: 0.8397 - lr: 2.0000e-04\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4775 - recall_2: 0.8550 - precision_2: 0.8086 - auc_1: 0.8965 - f1_score: 0.8311\n",
      "Epoch 8: val_f1_score improved from 0.84127 to 0.87805, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 27s 332ms/step - loss: 0.4775 - recall_2: 0.8550 - precision_2: 0.8086 - auc_1: 0.8965 - f1_score: 0.8311 - val_loss: 0.4479 - val_recall_2: 0.9153 - val_precision_2: 0.8438 - val_auc_1: 0.9262 - val_f1_score: 0.8780 - lr: 2.0000e-04\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4671 - recall_2: 0.8520 - precision_2: 0.8222 - auc_1: 0.9068 - f1_score: 0.8368\n",
      "Epoch 9: val_f1_score did not improve from 0.87805\n",
      "82/82 [==============================] - 27s 334ms/step - loss: 0.4671 - recall_2: 0.8520 - precision_2: 0.8222 - auc_1: 0.9068 - f1_score: 0.8368 - val_loss: 0.4446 - val_recall_2: 0.8983 - val_precision_2: 0.8548 - val_auc_1: 0.9245 - val_f1_score: 0.8760 - lr: 2.0000e-04\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4683 - recall_2: 0.8822 - precision_2: 0.7978 - auc_1: 0.9032 - f1_score: 0.8379\n",
      "Epoch 10: val_f1_score did not improve from 0.87805\n",
      "82/82 [==============================] - 28s 338ms/step - loss: 0.4683 - recall_2: 0.8822 - precision_2: 0.7978 - auc_1: 0.9032 - f1_score: 0.8379 - val_loss: 0.4458 - val_recall_2: 0.9153 - val_precision_2: 0.7714 - val_auc_1: 0.9234 - val_f1_score: 0.8372 - lr: 2.0000e-04\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4593 - recall_2: 0.8338 - precision_2: 0.8263 - auc_1: 0.9061 - f1_score: 0.8301\n",
      "Epoch 11: val_f1_score did not improve from 0.87805\n",
      "82/82 [==============================] - 28s 335ms/step - loss: 0.4593 - recall_2: 0.8338 - precision_2: 0.8263 - auc_1: 0.9061 - f1_score: 0.8301 - val_loss: 0.4473 - val_recall_2: 0.9322 - val_precision_2: 0.7639 - val_auc_1: 0.9339 - val_f1_score: 0.8397 - lr: 2.0000e-04\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4543 - recall_2: 0.8429 - precision_2: 0.8087 - auc_1: 0.9112 - f1_score: 0.8254\n",
      "Epoch 12: val_f1_score did not improve from 0.87805\n",
      "82/82 [==============================] - 27s 323ms/step - loss: 0.4543 - recall_2: 0.8429 - precision_2: 0.8087 - auc_1: 0.9112 - f1_score: 0.8254 - val_loss: 0.4106 - val_recall_2: 0.8475 - val_precision_2: 0.8621 - val_auc_1: 0.9387 - val_f1_score: 0.8547 - lr: 2.0000e-04\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4384 - recall_2: 0.8459 - precision_2: 0.8563 - auc_1: 0.9209 - f1_score: 0.8511\n",
      "Epoch 13: val_f1_score did not improve from 0.87805\n",
      "82/82 [==============================] - 27s 325ms/step - loss: 0.4384 - recall_2: 0.8459 - precision_2: 0.8563 - auc_1: 0.9209 - f1_score: 0.8511 - val_loss: 0.4202 - val_recall_2: 0.8983 - val_precision_2: 0.8154 - val_auc_1: 0.9373 - val_f1_score: 0.8548 - lr: 2.0000e-04\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4387 - recall_2: 0.8399 - precision_2: 0.8399 - auc_1: 0.9209 - f1_score: 0.8399\n",
      "Epoch 14: val_f1_score did not improve from 0.87805\n",
      "82/82 [==============================] - 28s 341ms/step - loss: 0.4387 - recall_2: 0.8399 - precision_2: 0.8399 - auc_1: 0.9209 - f1_score: 0.8399 - val_loss: 0.3946 - val_recall_2: 0.8814 - val_precision_2: 0.8525 - val_auc_1: 0.9485 - val_f1_score: 0.8667 - lr: 2.0000e-04\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4208 - recall_2: 0.8671 - precision_2: 0.8697 - auc_1: 0.9325 - f1_score: 0.8684\n",
      "Epoch 15: val_f1_score did not improve from 0.87805\n",
      "82/82 [==============================] - 27s 325ms/step - loss: 0.4208 - recall_2: 0.8671 - precision_2: 0.8697 - auc_1: 0.9325 - f1_score: 0.8684 - val_loss: 0.4324 - val_recall_2: 0.9322 - val_precision_2: 0.7971 - val_auc_1: 0.9451 - val_f1_score: 0.8594 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4195 - recall_2: 0.8610 - precision_2: 0.8584 - auc_1: 0.9332 - f1_score: 0.8597\n",
      "Epoch 16: val_f1_score improved from 0.87805 to 0.88136, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 27s 329ms/step - loss: 0.4195 - recall_2: 0.8610 - precision_2: 0.8584 - auc_1: 0.9332 - f1_score: 0.8597 - val_loss: 0.3938 - val_recall_2: 0.8814 - val_precision_2: 0.8814 - val_auc_1: 0.9517 - val_f1_score: 0.8814 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4226 - recall_2: 0.8550 - precision_2: 0.8576 - auc_1: 0.9318 - f1_score: 0.8563\n",
      "Epoch 17: val_f1_score did not improve from 0.88136\n",
      "82/82 [==============================] - 27s 327ms/step - loss: 0.4226 - recall_2: 0.8550 - precision_2: 0.8576 - auc_1: 0.9318 - f1_score: 0.8563 - val_loss: 0.3822 - val_recall_2: 0.8814 - val_precision_2: 0.8814 - val_auc_1: 0.9563 - val_f1_score: 0.8814 - lr: 2.0000e-04\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4232 - recall_2: 0.8761 - precision_2: 0.8430 - auc_1: 0.9295 - f1_score: 0.8593\n",
      "Epoch 18: val_f1_score did not improve from 0.88136\n",
      "82/82 [==============================] - 27s 326ms/step - loss: 0.4232 - recall_2: 0.8761 - precision_2: 0.8430 - auc_1: 0.9295 - f1_score: 0.8593 - val_loss: 0.3973 - val_recall_2: 0.9322 - val_precision_2: 0.8209 - val_auc_1: 0.9499 - val_f1_score: 0.8730 - lr: 2.0000e-04\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4181 - recall_2: 0.8792 - precision_2: 0.8687 - auc_1: 0.9347 - f1_score: 0.8739\n",
      "Epoch 19: val_f1_score improved from 0.88136 to 0.89256, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 27s 335ms/step - loss: 0.4181 - recall_2: 0.8792 - precision_2: 0.8687 - auc_1: 0.9347 - f1_score: 0.8739 - val_loss: 0.3756 - val_recall_2: 0.9153 - val_precision_2: 0.8710 - val_auc_1: 0.9564 - val_f1_score: 0.8926 - lr: 2.0000e-04\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4060 - recall_2: 0.8671 - precision_2: 0.8723 - auc_1: 0.9418 - f1_score: 0.8697\n",
      "Epoch 20: val_f1_score did not improve from 0.89256\n",
      "82/82 [==============================] - 27s 329ms/step - loss: 0.4060 - recall_2: 0.8671 - precision_2: 0.8723 - auc_1: 0.9418 - f1_score: 0.8697 - val_loss: 0.4138 - val_recall_2: 0.9492 - val_precision_2: 0.8116 - val_auc_1: 0.9487 - val_f1_score: 0.8750 - lr: 2.0000e-04\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3912 - recall_2: 0.8792 - precision_2: 0.8872 - auc_1: 0.9494 - f1_score: 0.8832\n",
      "Epoch 21: val_f1_score improved from 0.89256 to 0.90164, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 28s 337ms/step - loss: 0.3912 - recall_2: 0.8792 - precision_2: 0.8872 - auc_1: 0.9494 - f1_score: 0.8832 - val_loss: 0.3799 - val_recall_2: 0.9322 - val_precision_2: 0.8730 - val_auc_1: 0.9607 - val_f1_score: 0.9016 - lr: 2.0000e-04\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3924 - recall_2: 0.8610 - precision_2: 0.8879 - auc_1: 0.9480 - f1_score: 0.8742\n",
      "Epoch 22: val_f1_score did not improve from 0.90164\n",
      "82/82 [==============================] - 27s 327ms/step - loss: 0.3924 - recall_2: 0.8610 - precision_2: 0.8879 - auc_1: 0.9480 - f1_score: 0.8742 - val_loss: 0.3868 - val_recall_2: 0.8814 - val_precision_2: 0.8667 - val_auc_1: 0.9540 - val_f1_score: 0.8739 - lr: 2.0000e-04\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3884 - recall_2: 0.8792 - precision_2: 0.8926 - auc_1: 0.9498 - f1_score: 0.8858\n",
      "Epoch 23: val_f1_score did not improve from 0.90164\n",
      "82/82 [==============================] - 28s 338ms/step - loss: 0.3884 - recall_2: 0.8792 - precision_2: 0.8926 - auc_1: 0.9498 - f1_score: 0.8858 - val_loss: 0.3668 - val_recall_2: 0.8983 - val_precision_2: 0.8689 - val_auc_1: 0.9632 - val_f1_score: 0.8833 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3855 - recall_2: 0.8822 - precision_2: 0.8875 - auc_1: 0.9513 - f1_score: 0.8848\n",
      "Epoch 24: val_f1_score did not improve from 0.90164\n",
      "82/82 [==============================] - 27s 335ms/step - loss: 0.3855 - recall_2: 0.8822 - precision_2: 0.8875 - auc_1: 0.9513 - f1_score: 0.8848 - val_loss: 0.3692 - val_recall_2: 0.9322 - val_precision_2: 0.8730 - val_auc_1: 0.9673 - val_f1_score: 0.9016 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3800 - recall_2: 0.8882 - precision_2: 0.8829 - auc_1: 0.9548 - f1_score: 0.8855\n",
      "Epoch 25: val_f1_score did not improve from 0.90164\n",
      "82/82 [==============================] - 27s 327ms/step - loss: 0.3800 - recall_2: 0.8882 - precision_2: 0.8829 - auc_1: 0.9548 - f1_score: 0.8855 - val_loss: 0.3618 - val_recall_2: 0.8814 - val_precision_2: 0.9123 - val_auc_1: 0.9641 - val_f1_score: 0.8966 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3936 - recall_2: 0.8701 - precision_2: 0.8754 - auc_1: 0.9474 - f1_score: 0.8727\n",
      "Epoch 26: val_f1_score did not improve from 0.90164\n",
      "82/82 [==============================] - 28s 337ms/step - loss: 0.3936 - recall_2: 0.8701 - precision_2: 0.8754 - auc_1: 0.9474 - f1_score: 0.8727 - val_loss: 0.3625 - val_recall_2: 0.8644 - val_precision_2: 0.8947 - val_auc_1: 0.9646 - val_f1_score: 0.8793 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3800 - recall_2: 0.8882 - precision_2: 0.8936 - auc_1: 0.9546 - f1_score: 0.8909\n",
      "Epoch 27: val_f1_score did not improve from 0.90164\n",
      "82/82 [==============================] - 27s 325ms/step - loss: 0.3800 - recall_2: 0.8882 - precision_2: 0.8936 - auc_1: 0.9546 - f1_score: 0.8909 - val_loss: 0.3637 - val_recall_2: 0.8983 - val_precision_2: 0.8689 - val_auc_1: 0.9620 - val_f1_score: 0.8833 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3692 - recall_2: 0.9184 - precision_2: 0.8915 - auc_1: 0.9589 - f1_score: 0.9048\n",
      "Epoch 28: val_f1_score did not improve from 0.90164\n",
      "82/82 [==============================] - 27s 333ms/step - loss: 0.3692 - recall_2: 0.9184 - precision_2: 0.8915 - auc_1: 0.9589 - f1_score: 0.9048 - val_loss: 0.3840 - val_recall_2: 0.9153 - val_precision_2: 0.8710 - val_auc_1: 0.9567 - val_f1_score: 0.8926 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3612 - recall_2: 0.9063 - precision_2: 0.8876 - auc_1: 0.9633 - f1_score: 0.8969\n",
      "Epoch 29: val_f1_score improved from 0.90164 to 0.91935, saving model to /Users/tousif/Lstm_transformer/KD_Multimodal/tmp/weights.ckpt\n",
      "82/82 [==============================] - 27s 332ms/step - loss: 0.3612 - recall_2: 0.9063 - precision_2: 0.8876 - auc_1: 0.9633 - f1_score: 0.8969 - val_loss: 0.3531 - val_recall_2: 0.9661 - val_precision_2: 0.8769 - val_auc_1: 0.9729 - val_f1_score: 0.9194 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3583 - recall_2: 0.9063 - precision_2: 0.9063 - auc_1: 0.9640 - f1_score: 0.9063\n",
      "Epoch 30: val_f1_score did not improve from 0.91935\n",
      "82/82 [==============================] - 27s 334ms/step - loss: 0.3583 - recall_2: 0.9063 - precision_2: 0.9063 - auc_1: 0.9640 - f1_score: 0.9063 - val_loss: 0.3650 - val_recall_2: 0.9153 - val_precision_2: 0.8571 - val_auc_1: 0.9664 - val_f1_score: 0.8852 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3624 - recall_2: 0.8912 - precision_2: 0.9077 - auc_1: 0.9637 - f1_score: 0.8994\n",
      "Epoch 31: val_f1_score did not improve from 0.91935\n",
      "82/82 [==============================] - 27s 336ms/step - loss: 0.3624 - recall_2: 0.8912 - precision_2: 0.9077 - auc_1: 0.9637 - f1_score: 0.8994 - val_loss: 0.3701 - val_recall_2: 0.9661 - val_precision_2: 0.8507 - val_auc_1: 0.9670 - val_f1_score: 0.9048 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3612 - recall_2: 0.9305 - precision_2: 0.8980 - auc_1: 0.9611 - f1_score: 0.9139\n",
      "Epoch 32: val_f1_score did not improve from 0.91935\n",
      "82/82 [==============================] - 28s 340ms/step - loss: 0.3612 - recall_2: 0.9305 - precision_2: 0.8980 - auc_1: 0.9611 - f1_score: 0.9139 - val_loss: 0.4255 - val_recall_2: 0.9492 - val_precision_2: 0.8485 - val_auc_1: 0.9469 - val_f1_score: 0.8960 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3569 - recall_2: 0.9033 - precision_2: 0.9116 - auc_1: 0.9658 - f1_score: 0.9074\n",
      "Epoch 33: val_f1_score did not improve from 0.91935\n",
      "82/82 [==============================] - 27s 328ms/step - loss: 0.3569 - recall_2: 0.9033 - precision_2: 0.9116 - auc_1: 0.9658 - f1_score: 0.9074 - val_loss: 0.3795 - val_recall_2: 0.9492 - val_precision_2: 0.8750 - val_auc_1: 0.9640 - val_f1_score: 0.9106 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.3567 - recall_2: 0.9033 - precision_2: 0.9116 - auc_1: 0.9640 - f1_score: 0.9074\n",
      "Epoch 34: val_f1_score did not improve from 0.91935\n",
      "82/82 [==============================] - 29s 348ms/step - loss: 0.3567 - recall_2: 0.9033 - precision_2: 0.9116 - auc_1: 0.9640 - f1_score: 0.9074 - val_loss: 0.3620 - val_recall_2: 0.9322 - val_precision_2: 0.8594 - val_auc_1: 0.9634 - val_f1_score: 0.8943 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "    model = None\n",
    "    dataset_path = os.path.join(os.getcwd(), 'fall_detection_dataset.npz')\n",
    "    f = np.load(dataset_path)\n",
    "    signals = f['trials']\n",
    "\n",
    "    labels = f['labels']\n",
    "\n",
    "    # split to train-test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        signals, labels, test_size=0.15, random_state=9, stratify=labels\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.15, random_state=9, stratify=y_train\n",
    "    )\n",
    "\n",
    "    # sweep_id = wandb.sweep(sweep_config, project=\"KD_Transformer\")\n",
    "    with tf.device('/gpu:0'):\n",
    "      model = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d281ab",
   "metadata": {},
   "source": [
    "### Loading the Best Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6b4d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "#Just to build the model first, we called this evaluate\n",
    "model.evaluate(X_test, y_test, batch_size=8, steps=X_test.shape[0]/8)\n",
    "\n",
    "#loading best weights and evaluating\n",
    "weight_path = 'tmp/weights.ckpt'\n",
    "model.load_weights(weight_path)\n",
    "model.evaluate(X_test, y_test, batch_size=8, steps=X_test.shape[0]/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78646dc8",
   "metadata": {},
   "source": [
    "## Ploting ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc88dd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 162ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).ravel()\n",
    "fp_pred, tp_pred, threshold_pred = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "231174bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = auc(fp_pred, tp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b598cd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot([0,1], [0, 1], 'k--')\n",
    "plt.plot(fp_pred, tp_pred, label = 'SmartFall (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537d01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
